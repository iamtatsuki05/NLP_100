{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mlf0v2adFGzT"
   },
   "source": [
    "# ニューラルネット\n",
    "## 第6章で取り組んだニュース記事のカテゴリ分類を題材として，ニューラルネットワークでカテゴリ分類モデルを実装する．なお，この章ではPyTorch, TensorFlow, Chainerなどの機械学習プラットフォームを活用せよ．\n",
    "\n",
    "\n",
    "\n",
    "####https://nlp100.github.io/ja/ch08.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5efGfGAXJcy3"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/iamtatsuki05/NLP_100/blob/fix_all_merge/NLP_100_8.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18387,
     "status": "ok",
     "timestamp": 1649242055480,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "jBYlYY_Q7o3R",
    "outputId": "5d88f2fe-ae9c-4201-cbcc-9d6f97ee8126"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ap0ufgsdFG2U"
   },
   "source": [
    "# 単語ベクトルの和による特徴量\n",
    "## 問題50で構築した学習データ，検証データ，評価データを行列・ベクトルに変換したい．例えば，学習データについて，すべての事例xiの特徴ベクトルxiを並べた行列Xと，正解ラベルを並べた行列（ベクトル）Yを作成したい．\n",
    "\n",
    "X=⎛⎝⎜⎜⎜⎜x1x2…xn⎞⎠⎟⎟⎟⎟∈ℝn×d,Y=⎛⎝⎜⎜⎜⎜y1y2…yn⎞⎠⎟⎟⎟⎟∈ℕn\n",
    "ここで，nは学習データの事例数であり，xi∈ℝdとyi∈ℕはそれぞれ，i∈{1,…,n}番目の事例の特徴量ベクトルと正解ラベルを表す． なお，今回は「ビジネス」「科学技術」「エンターテイメント」「健康」の4カテゴリ分類である．ℕ<4で4未満の自然数（0を含む）を表すことにすれば，任意の事例の正解ラベルyiはyi∈ℕ<4で表現できる． 以降では，ラベルの種類数をLで表す（今回の分類タスクではL=4である）．\n",
    "\n",
    "i番目の事例の特徴ベクトルxiは，次式で求める．\n",
    "\n",
    "xi=1Ti∑t=1Tiemb(wi,t)\n",
    "ここで，i番目の事例はTi個の（記事見出しの）単語列(wi,1,wi,2,…,wi,Ti)から構成され，emb(w)∈ℝdは単語wに対応する単語ベクトル（次元数はd）である．すなわち，i番目の事例の記事見出しを，その見出しに含まれる単語のベクトルの平均で表現したものがxiである．今回は単語ベクトルとして，問題60でダウンロードしたものを用いればよい．300次元の単語ベクトルを用いたので，d=300である．\n",
    "\n",
    "i番目の事例のラベルyiは，次のように定義する．\n",
    "\n",
    "yi=⎧⎩⎨⎪⎪0123(記事xiが「ビジネス」カテゴリの場合)(記事xiが「科学技術」カテゴリの場合)(記事xiが「エンターテイメント」カテゴリの場合)(記事xiが「健康」カテゴリの場合)\n",
    "なお，カテゴリ名とラベルの番号が一対一で対応付いていれば，上式の通りの対応付けでなくてもよい．\n",
    "\n",
    "以上の仕様に基づき，以下の行列・ベクトルを作成し，ファイルに保存せよ．\n",
    "\n",
    "学習データの特徴量行列: Xtrain∈ℝNt×d\n",
    "学習データのラベルベクトル: Ytrain∈ℕNt\n",
    "検証データの特徴量行列: Xvalid∈ℝNv×d\n",
    "検証データのラベルベクトル: Yvalid∈ℕNv\n",
    "評価データの特徴量行列: Xtest∈ℝNe×d\n",
    "評価データのラベルベクトル: Ytest∈ℕNe\n",
    "なお，Nt,Nv,Neはそれぞれ，学習データの事例数，検証データの事例数，評価データの事例数である．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2692,
     "status": "ok",
     "timestamp": 1649242058166,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "19jS0MThblNJ",
    "outputId": "69f17cfa-cbe4-4e1f-bc65-c0ae3306ff16"
   },
   "outputs": [],
   "source": [
    "# 学習データの特徴量行列: Xtrain\n",
    "# 学習データのラベルベクトル: Ytrain\n",
    "# 検証データの特徴量行列: Xvalid\n",
    "# 検証データのラベルベクトル: Yvalid\n",
    "# 評価データの特徴量行列: Xtest\n",
    "# 評価データのラベルベクトル: Ytest\n",
    "# Nt,Nv,Ne はそれぞれ，学習データの事例数，検証データの事例数，評価データの事例数．\n",
    "\n",
    "# 問題50のデータをもう一度作成します。\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip\n",
    "!unzip NewsAggregatorDataset.zip\n",
    "fin = open('readme.txt', 'r')\n",
    "data = fin.read()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3138,
     "status": "ok",
     "timestamp": 1649242061302,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "I-aV9-2idTUF"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('/content/newsCorpora.csv', header=None, sep='\\t', names=['ID', 'TITLE', 'URL', 'PUBLISHER', 'CATEGORY', 'STORY', 'HOSTNAME', 'TIMESTAMP'])\n",
    "df = df.loc[df['PUBLISHER'].isin(['Reuters', 'Huffington Post', 'Businessweek', 'Contactmusic.com', 'Daily Mail']), ['TITLE', 'CATEGORY']]\n",
    "\n",
    "test, train_valid = train_test_split(df, test_size=0.8, shuffle=True, random_state=42, stratify=df['CATEGORY'])\n",
    "valid, train = train_test_split(train_valid, test_size=0.25, shuffle=True, random_state=42, stratify=train_valid['CATEGORY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1649242061302,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "piq55DBKQQ1j"
   },
   "outputs": [],
   "source": [
    "# ダウンロード制限がかかっているのでprthを指定する\n",
    "# #参考https://qiita.com/jun40vn/items/0f9bd5353197d3f14f3e\n",
    "# ! pip install --upgrade gdown\n",
    "# import gdown\n",
    "# gdown.download('https://drive.google.com/u/0/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&export=download', './GoogleNews-vectors-negative300.bin.gz', quiet=False)\n",
    "# from gensim.models import KeyedVectors\n",
    "# model_kv = KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin.gz' , binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 145568,
     "status": "ok",
     "timestamp": 1649242206868,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "ymREuxqEIWcx"
   },
   "outputs": [],
   "source": [
    "# 直接pathを指定する場合\n",
    "from gensim.models import KeyedVectors\n",
    "model_kv = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/Tutorial/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5316,
     "status": "ok",
     "timestamp": 1649242212172,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "0VvqS1hYIuZf"
   },
   "outputs": [],
   "source": [
    "# 特徴ベクトル化\n",
    "import torch\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "# 6章と同様の処理\n",
    "def extract(text):\n",
    "     # 記号変換\n",
    "    table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "    words = text.translate(table).split()\n",
    "    # テンソル化\n",
    "    vectors = [model_kv[word] for word in words if word in model_kv]\n",
    "\n",
    "    return torch.tensor(sum(vectors) / len(vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1200,
     "status": "ok",
     "timestamp": 1649242213363,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "C9zZavsgBG96",
    "outputId": "d4004c51-7bc9-4ae8-8135-568b28007c45"
   },
   "outputs": [],
   "source": [
    "X_train = torch.stack([extract(text) for text in train['TITLE']])\n",
    "X_valid = torch.stack([extract(text) for text in valid['TITLE']])\n",
    "X_test = torch.stack([extract(text) for text in test['TITLE']])\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1649242213363,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "vI76bqPLKZZc",
    "outputId": "52f8f506-b78d-43f8-c166-be59d4de8dfe"
   },
   "outputs": [],
   "source": [
    "# ラベル\n",
    "label_map = {'b': 0, 't': 1, 'e': 2, 'm': 3}\n",
    "y_train = torch.LongTensor(train['CATEGORY'].map(lambda x: label_map[x]).values)\n",
    "y_valid = torch.LongTensor(valid['CATEGORY'].map(lambda x: label_map[x]).values)\n",
    "y_test = torch.LongTensor(test['CATEGORY'].map(lambda x: label_map[x]).values)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1649242213364,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "XyB_joXyIuRN"
   },
   "outputs": [],
   "source": [
    "# 参考https://tzmi.hatenablog.com/entry/2020/01/27/001036\n",
    "# https://panda-clip.com/torch-stack/\n",
    "# https://www.hellocybernetics.tech/entry/2017/10/19/070522\n",
    "# https://codezine.jp/article/detail/11052\n",
    "# https://qiita.com/jyori112/items/aad5703c1537c0139edb\n",
    "# https://pytorch.org/docs/stable/generated/torch.save.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLQupFd_FG7y"
   },
   "source": [
    "# 単層ニューラルネットワークによる予測\n",
    "## 問題70で保存した行列を読み込み，学習データについて以下の計算を実行せよ．\n",
    "\n",
    "ŷ 1=softmax(x1W),Ŷ =softmax(X[1:4]W)\n",
    "ただし，softmaxはソフトマックス関数，X[1:4]∈ℝ4×dは特徴ベクトルx1,x2,x3,x4を縦に並べた行列である．\n",
    "\n",
    "X[1:4]=⎛⎝⎜⎜⎜⎜x1x2x3x4⎞⎠⎟⎟⎟⎟\n",
    "行列W∈ℝd×Lは単層ニューラルネットワークの重み行列で，ここではランダムな値で初期化すればよい（問題73以降で学習して求める）．なお，ŷ 1∈ℝLは未学習の行列Wで事例x1を分類したときに，各カテゴリに属する確率を表すベクトルである． 同様に，Ŷ ∈ℝn×Lは，学習データの事例x1,x2,x3,x4について，各カテゴリに属する確率を行列として表現している．\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1649242213364,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "1DM0M_Ude7KM",
    "outputId": "0184f389-d4a3-4a69-9462-b4f95fb7098f"
   },
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# X_train = torch.tensor(X_train , requires_grad=True)\n",
    "# W = torch.randn(300 , 4)\n",
    "# softmax = torch.nn.Softmax(dim=-1)\n",
    "# print (f'1 : {softmax(torch.matmul(X_train[:1] , W))}')\n",
    "# print (f'4 : {softmax(torch.matmul(X_train[:4] , W))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1649242213364,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "LCihBotqlR_L"
   },
   "outputs": [],
   "source": [
    "class ModelLn(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size, bias=False)\n",
    "        nn.init.normal_(self.fc.weight, 0.0, 1.0)  # 正規乱数で重みを初期化\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1649242213365,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "94ewFJOYlieq",
    "outputId": "533c0626-bfcc-4e3f-e462-af8c8d87f94f"
   },
   "outputs": [],
   "source": [
    "model = ModelLn(300, 4)  # 単層ニューラルネットワークの初期化\n",
    "l_1 = torch.softmax(model(X_train[:1]), dim=-1)\n",
    "print(l_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1649242213365,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "xb3NC5g3nFnE",
    "outputId": "65088415-87d1-4ee4-e0a1-377b6d63d662"
   },
   "outputs": [],
   "source": [
    "l_4 = torch.softmax(model(X_train[:1]), dim=-1)\n",
    "print(l_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1649242213365,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "XdYaPlVqTmlu"
   },
   "outputs": [],
   "source": [
    "# 参考https://qiita.com/mathlive/items/2c67efa2d451ea1da1b1\n",
    "# https://watlab-blog.com/2021/06/13/pytorch-nn-class/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qT31R91uFG-w"
   },
   "source": [
    "# 損失と勾配の計算\n",
    "## 学習データの事例x1と事例集合x1,x2,x3,x4に対して，クロスエントロピー損失と，行列Wに対する勾配を計算せよ．なお，ある事例xiに対して損失は次式で計算される．\n",
    "\n",
    "li=−log[事例xiがyiに分類される確率]\n",
    "ただし，事例集合に対するクロスエントロピー損失は，その集合に含まれる各事例の損失の平均とする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1649242213365,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "-2sRgo4Le76a",
    "outputId": "d6da501b-4b9c-4466-d9ab-bfef6fd65de4"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#_1\n",
    "l_1 = criterion(model(X_train[:1]), y_train[:1])\n",
    "model.zero_grad()\n",
    "l_1.backward()# 誤差算出\n",
    "\n",
    "print(f'クロスエントロピー損失 : {l_1}')\n",
    "print(f'勾配 : {model.fc.weight.grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1649242213366,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "MfrIBTEcuIA4",
    "outputId": "e1020289-209b-4407-92e4-16a312c476fa"
   },
   "outputs": [],
   "source": [
    "#_4\n",
    "l_4 = criterion(model(X_train[:4]), y_train[:4])\n",
    "model.zero_grad()\n",
    "l_4.backward()\n",
    "\n",
    "print(f'クロスエントロピー損失 : {l_4}')\n",
    "print(f'勾配 : {model.fc.weight.grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1649242213366,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "GZO5IFmpjUa2"
   },
   "outputs": [],
   "source": [
    "# 参考https://qiita.com/maechanneler/items/8f10a758d7d3431ae61f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQB9mSC0FHBg"
   },
   "source": [
    "# 確率的勾配降下法による学習\n",
    "## 確率的勾配降下法（SGD: Stochastic Gradient Descent）を用いて，行列Wを学習せよ．なお，学習は適当な基準で終了させればよい（例えば「100エポックで終了」など）．\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1649242213754,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "Wijq0zPwEcVY"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class WordVecDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1649242213754,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "D-Ogmxl8EqeH"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset_train = WordVecDataset(X_train, y_train)\n",
    "dataset_valid = WordVecDataset(X_valid, y_valid)\n",
    "dataset_test = WordVecDataset(X_test, y_test)\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=1 , shuffle=True)#混ぜる\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=len(dataset_valid), shuffle=False)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=len(dataset_test), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1649242213755,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "dBS675QJI54t"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15712,
     "status": "ok",
     "timestamp": 1649242229464,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "tJdY9edRAktE",
    "outputId": "4f307a0c-2724-4c52-d52c-7c3b32a8ce0d"
   },
   "outputs": [],
   "source": [
    "#時間がかかるので少なめに設定する\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    loss_train = 0.0\n",
    "    for i, (inputs, labels) in enumerate(dataloader_train):\n",
    "        optimizer.zero_grad()#加算されてしまうのでリセット\n",
    "        y_pred = model(inputs)#modelを用いて予測\n",
    "        loss = criterion(y_pred, labels)#誤差\n",
    "        loss.backward()#誤差修正\n",
    "        optimizer.step()#更新\n",
    "        loss_train += loss.item()#誤差\n",
    "\n",
    "    loss_train = loss_train / i#平均誤差\n",
    "    # 検証データ\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        inputs, labels = next(iter(dataloader_valid))\n",
    "        outputs = model(inputs)\n",
    "        loss_valid = criterion(outputs, labels)\n",
    "\n",
    "    print(f'epoch: {epoch + 1} , loss_train: {loss_train} , loss_valid: {loss_valid}')                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1649242229464,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "cmRmOUa5cvaQ"
   },
   "outputs": [],
   "source": [
    "# 参考https://qiita.com/mathlive/items/2c67efa2d451ea1da1b1\n",
    "# https://pytorch.org/docs/stable/optim.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7_iLBR2FHDu"
   },
   "source": [
    "# 正解率の計測\n",
    "\n",
    "\n",
    "## 問題73で求めた行列を用いて学習データおよび評価データの事例を分類したとき，その正解率をそれぞれ求めよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1649242229465,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "ef6ElOqaI485"
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# result_test = model_ln(X_test)\n",
    "# train_score = accuracy_score(y_train / result)\n",
    "# test_score = accuracy_score(y_test / result_test)\n",
    "# print(f'train-score : {train_score}')\n",
    "# print(f'test-score : {test_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1649242229465,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "su6H2tUrJ3yK"
   },
   "outputs": [],
   "source": [
    "def calc_score(model, loader):\n",
    "    model.eval()\n",
    "    y_true = 0\n",
    "    y_pred = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            outputs = model(inputs)\n",
    "            pred = torch.argmax(outputs, dim=-1)\n",
    "            y_true += len(inputs)\n",
    "            y_pred += (pred == labels).sum().item()\n",
    "\n",
    "    return y_pred / y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1649242229884,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "bt_2oUHDLdXG",
    "outputId": "6d2ffe39-c34f-4486-ff2c-9801e8355bc8"
   },
   "outputs": [],
   "source": [
    "score_train = calc_score(model , dataloader_train)\n",
    "score_test = calc_score(model , dataloader_test)\n",
    "print(f'train_accuracy : {score_train}')\n",
    "print(f'valid_accuracy : {score_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1649242229886,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "fqUN_VtKJicB"
   },
   "outputs": [],
   "source": [
    "# 参考https://qiita.com/Haaamaaaaa/items/b9f47cba588b83ad34a7\n",
    "# https://note.nkmk.me/python-pytorch-tensor-item/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6r-LVu0EFHGV"
   },
   "source": [
    "# 損失と正解率のプロット\n",
    "\n",
    "\n",
    "## 問題73のコードを改変し，各エポックのパラメータ更新が完了するたびに，訓練データでの損失，正解率，検証データでの損失，正解率をグラフにプロットし，学習の進捗状況を確認できるようにせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1649242229887,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "H1XHbT0hh9xT"
   },
   "outputs": [],
   "source": [
    "def calc_loss_and_acc(model, criterion, loader):\n",
    "    model.eval()\n",
    "    loss = 0.0\n",
    "    y_true = 0\n",
    "    y_pred = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            outputs = model(inputs)\n",
    "            loss += criterion(outputs, labels).item()#new\n",
    "            pred = torch.argmax(outputs, dim=-1)\n",
    "            y_true += len(inputs)\n",
    "            y_pred += (pred == labels).sum().item()\n",
    "\n",
    "    return loss / len(loader), y_pred / y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20961,
     "status": "ok",
     "timestamp": 1649242250843,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "h_0g3senNQvt",
    "outputId": "d74e38bd-4150-4986-d437-40ca35141bef"
   },
   "outputs": [],
   "source": [
    "#時間がかかるので少なめに設定する\n",
    "log_train = []\n",
    "log_valid = []\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    for inputs, labels in dataloader_train:\n",
    "        optimizer.zero_grad()#加算されてしまうのでリセット\n",
    "        y_pred = model(inputs)#modelを用いて予測\n",
    "        loss = criterion(y_pred, labels)#誤差\n",
    "        loss.backward()#誤差修正\n",
    "        optimizer.step()#更新\n",
    "\n",
    "    # 正解率等の計算\n",
    "    loss_train, acc_train = calc_loss_and_acc(model, criterion, dataloader_train)\n",
    "    loss_valid, acc_valid = calc_loss_and_acc(model, criterion, dataloader_valid)\n",
    "    log_train.append([loss_train, acc_train])\n",
    "    log_valid.append([loss_valid, acc_valid])\n",
    "\n",
    "    # ログを出力\n",
    "    print(f'epoch : {epoch + 1} , loss_train : {loss_train} , accuracy_train : {acc_train} , loss_valid : {loss_valid} , accuracy_valid: {acc_valid}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 845,
     "status": "ok",
     "timestamp": 1649242251687,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "VgGuPxPINv0w",
    "outputId": "6332c256-063c-4b82-e6f7-c166b0876ed9"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(25, 10))\n",
    "#loss_epoch\n",
    "ax[0].plot(np.array(log_train).T[0], label='train')\n",
    "ax[0].plot(np.array(log_valid).T[0], label='valid')\n",
    "ax[0].set_xlabel('回数')\n",
    "ax[0].set_ylabel('損失')\n",
    "ax[0].legend()\n",
    "#acc_epoch\n",
    "ax[1].plot(np.array(log_train).T[1], label='train')\n",
    "ax[1].plot(np.array(log_valid).T[1], label='valid')\n",
    "ax[1].set_xlabel('回数')\n",
    "ax[1].set_ylabel('正答率')\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1649242251687,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "m5M3_xPJb6Vz"
   },
   "outputs": [],
   "source": [
    "# 参考https://yoshinashigoto-blog.herokuapp.com/detail/30/\n",
    "# https://exture-ri.com/2021/01/04/pytorch-nn/\n",
    "# https://yoshinashigoto-blog.herokuapp.com/detail/27/\n",
    "# https://qiita.com/noknmgc/items/3b8531266e8986ca63fe\n",
    "# https://qiita.com/awawaInu/items/e173acded17a142e6d02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rc0r4dkvFHIm"
   },
   "source": [
    "# チェックポイント\n",
    "## 問題75のコードを改変し，各エポックのパラメータ更新が完了するたびに，チェックポイント（学習途中のパラメータ（重み行列など）の値や最適化アルゴリズムの内部状態）をファイルに書き出せ．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20995,
     "status": "ok",
     "timestamp": 1649242272679,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "1_lkbSK5I3qI",
    "outputId": "fed889d8-2bd9-4111-b5a0-fad7de3ce925"
   },
   "outputs": [],
   "source": [
    "#時間がかかるので少なめに設定する\n",
    "log_train = []\n",
    "log_valid = []\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    for inputs, labels in dataloader_train:\n",
    "        optimizer.zero_grad()#加算されてしまうのでリセット\n",
    "        y_pred = model(inputs)#modelを用いて予測\n",
    "        loss = criterion(y_pred, labels)#誤差\n",
    "        loss.backward()#誤差修正\n",
    "        optimizer.step()#更新\n",
    "\n",
    "    # 正解率等の計算\n",
    "    loss_train, acc_train = calc_loss_and_acc(model, criterion, dataloader_train)\n",
    "    loss_valid, acc_valid = calc_loss_and_acc(model, criterion, dataloader_valid)\n",
    "    log_train.append([loss_train, acc_train])\n",
    "    log_valid.append([loss_valid, acc_valid])\n",
    "\n",
    "    # チェックポイント new\n",
    "    torch.save({'epoch' : epoch , 'model_state_dict' : model.state_dict() , 'optimizer_state_dict' : optimizer.state_dict()} , f'checkpoint{epoch + 1}.pt')\n",
    "\n",
    "    # ログを出力\n",
    "    print(f'epoch : {epoch + 1} , loss_train : {loss_train} , accuracy_train : {acc_train} , loss_valid : {loss_valid} , accuracy_valid: {acc_valid}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJmQqI3PFHLE"
   },
   "source": [
    "# ミニバッチ化\n",
    "## 問題76のコードを改変し，B事例ごとに損失・勾配を計算し，行列Wの値を更新せよ（ミニバッチ化）．Bの値を1,2,4,8,…と変化させながら，1エポックの学習に要する時間を比較せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1649242272680,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "kPnqqX1XI1r6"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_minibatch_model(dataset_train, dataset_valid, batch_size, model, criterion, optimizer, epochs):\n",
    "    # dataloaderの作成\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "    dataloader_valid = DataLoader(dataset_valid, batch_size=len(dataset_valid), shuffle=False)\n",
    "\n",
    "    # 学習\n",
    "    log_train = []\n",
    "    log_valid = []\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()#計測開始\n",
    "        model.train()\n",
    "\n",
    "        for inputs, labels in dataloader_train:\n",
    "            optimizer.zero_grad()#加算されてしまうのでリセット\n",
    "            y_pred = model(inputs)#modelを用いて予測\n",
    "            loss = criterion(y_pred, labels)#誤差\n",
    "            loss.backward()#誤差修正\n",
    "            optimizer.step()#更新\n",
    "\n",
    "        # 正解率等の計算\n",
    "        loss_train, acc_train = calc_loss_and_acc(model, criterion, dataloader_train)\n",
    "        loss_valid, acc_valid = calc_loss_and_acc(model, criterion, dataloader_valid)\n",
    "        log_train.append([loss_train, acc_train])\n",
    "        log_valid.append([loss_valid, acc_valid])\n",
    "\n",
    "        # # チェックポイント new\n",
    "        # torch.save({'epoch' : epoch , 'model_state_dict' : model.state_dict() , 'optimizer_state_dict' : optimizer.state_dict()} , f'checkpoint{epoch + 1}.pt')\n",
    "\n",
    "        end = time.time()#計測完了\n",
    "\n",
    "        # ログを出力\n",
    "        print(f'epoch : {epoch + 1} , loss_train : {loss_train} , accuracy_train : {acc_train} , loss_valid : {loss_valid} , accuracy_valid : {acc_valid} , {end - start} sec') \n",
    "\n",
    "    return {'train' : log_train , 'valid' : log_valid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2315,
     "status": "ok",
     "timestamp": 1649242274980,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "yiQQGOyxbiwW",
    "outputId": "a7def59e-4850-4075-f585-e7bb57b26135"
   },
   "outputs": [],
   "source": [
    "for batch_size in [2 ** i for i in range(5)]:\n",
    "    print(f'バッチサイズ : {batch_size}')\n",
    "    log = train_minibatch_model(dataset_train, dataset_valid, batch_size, model, criterion, optimizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1649242274980,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "gom7ZEBtsnrQ"
   },
   "outputs": [],
   "source": [
    "# 参考https://gotutiyan.hatenablog.com/entry/2020/04/21/182937\n",
    "# https://tzmi.hatenablog.com/entry/2020/04/11/234417\n",
    "# https://qiita.com/kimisyo/items/9508aff5a25e70772d5c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3DmpIYkFHNo"
   },
   "source": [
    "# GPU上での学習\n",
    "## 問題77のコードを改変し，GPU上で学習を実行せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1649242274980,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "vf_hpNBLl1e1"
   },
   "outputs": [],
   "source": [
    "def calc_loss_acc_gpu(model, criterion, loader, device):\n",
    "    model.eval()\n",
    "    loss = 0.0\n",
    "    y_true = 0\n",
    "    y_pred = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "\n",
    "            inputs = inputs.to(device)#gpu\n",
    "            labels = labels.to(device)#gpu\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss += criterion(outputs, labels).item()#new\n",
    "            pred = torch.argmax(outputs, dim=-1)\n",
    "            y_true += len(inputs)\n",
    "            y_pred += (pred == labels).sum().item()\n",
    "\n",
    "    return loss / len(loader), y_pred / y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1649242274981,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "gCpgEzA_o7Q9"
   },
   "outputs": [],
   "source": [
    "def train_minibatch_model(dataset_train, dataset_valid, batch_size, model, criterion, optimizer, epochs, device=None):\n",
    "    model.to(device)#gpu\n",
    "    # dataloaderの作成\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "    dataloader_valid = DataLoader(dataset_valid, batch_size=len(dataset_valid), shuffle=False)\n",
    "\n",
    "    # 学習\n",
    "    log_train = []\n",
    "    log_valid = []\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()#計測開始\n",
    "        model.train()\n",
    "\n",
    "        for inputs, labels in dataloader_train:\n",
    "            optimizer.zero_grad()#加算されてしまうのでリセット\n",
    "\n",
    "            inputs = inputs.to(device)#gpu\n",
    "            labels = labels.to(device)#gpu\n",
    "\n",
    "            y_pred = model(inputs)#modelを用いて予測\n",
    "            loss = criterion(y_pred, labels)#誤差\n",
    "            loss.backward()#誤差修正\n",
    "            optimizer.step()#更新\n",
    "\n",
    "        # 正解率等の計算\n",
    "        loss_train, acc_train = calc_loss_acc_gpu(model, criterion, dataloader_train, device)#gpu\n",
    "        loss_valid, acc_valid = calc_loss_acc_gpu(model, criterion, dataloader_valid, device)#gpu\n",
    "        log_train.append([loss_train, acc_train])\n",
    "        log_valid.append([loss_valid, acc_valid])\n",
    "\n",
    "        # # チェックポイント new\n",
    "        # torch.save({'epoch' : epoch , 'model_state_dict' : model.state_dict() , 'optimizer_state_dict' : optimizer.state_dict()} , f'checkpoint{epoch + 1}.pt')\n",
    "\n",
    "        end = time.time()#計測完了\n",
    "\n",
    "        # ログを出力\n",
    "        print(f'epoch : {epoch + 1} , loss_train : {loss_train} , accuracy_train : {acc_train} , loss_valid : {loss_valid} , accuracy_valid : {acc_valid} , {end - start} sec') \n",
    "\n",
    "    return {'train' : log_train , 'valid' : log_valid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2302,
     "status": "ok",
     "timestamp": 1649242277280,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "AAJS13PZbrWU",
    "outputId": "f4e322ab-dcf6-4ab2-d473-0eb94357a031"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "for batch_size in [2 ** i for i in range(4)]:\n",
    "    print(f'バッチサイズ : {batch_size}')\n",
    "    log = train_minibatch_model(dataset_train, dataset_valid, batch_size, model, criterion, optimizer, 1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1649242277280,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "CKGLQYW3sQcX"
   },
   "outputs": [],
   "source": [
    "# 参考https://note.nkmk.me/python-pytorch-cuda-is-available-device-count/\n",
    "# https://atmarkit.itmedia.co.jp/ait/articles/2008/28/news030.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LonpamKPFHQA"
   },
   "source": [
    "# 多層ニューラルネットワーク\n",
    "## 問題78のコードを改変し，バイアス項の導入や多層化など，ニューラルネットワークの形状を変更しながら，高性能なカテゴリ分類器を構築せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1649242277281,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "_RrLo55OI0Y_"
   },
   "outputs": [],
   "source": [
    "# class model_ln_layers(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "#         super().__init__()\n",
    "#         self.num_layers = num_layers\n",
    "#         self.fc = nn.Linear(input_size, hidden_size)\n",
    "#         self.fc_mid = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "#         self.bn = nn.BatchNorm1d(hidden_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.fc(x))\n",
    "#         for _ in range(self.num_layers):\n",
    "#             x = F.relu(self.bn(self.fc_mid(x)))\n",
    "#         x = F.relu(self.fc_out(x))\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1649242277281,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "Ia3E6eRg6mOU"
   },
   "outputs": [],
   "source": [
    "# #時間がかかるので少なめに設定する\n",
    "# model = model_ln_layers(300, 200, 4, 5)\n",
    "\n",
    "# log = train_model(dataset_train, dataset_valid, 64, model, criterion, optimizer, 20, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1649242277281,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "ID7DHmbzGoF3"
   },
   "outputs": [],
   "source": [
    "class model_ln_layers(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_size, hidden_size)\n",
    "        self.fc_mid_1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc_mid_2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc_mid_3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "        self.bn = nn.BatchNorm1d(hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc(x))\n",
    "        x = F.relu(self.bn(self.fc_mid_1(x)))\n",
    "        x = F.relu(self.bn(self.fc_mid_2(x)))\n",
    "        x = F.relu(self.bn(self.fc_mid_3(x)))\n",
    "        x = F.relu(self.fc_out(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6651,
     "status": "ok",
     "timestamp": 1649242283929,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "FqGlEfleGqMV",
    "outputId": "5b1a950f-2899-43cc-c58a-c36c2dabab60"
   },
   "outputs": [],
   "source": [
    "model = model_ln_layers(300, 200, 4)\n",
    "\n",
    "log = train_model(dataset_train, dataset_valid, 64, model, criterion, optimizer, 20, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1649242283929,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "knpTZNHNdHBS"
   },
   "outputs": [],
   "source": [
    "# class Net(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, output_size):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "#         self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.fc4 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.fc5 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.fc6 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "         \n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = F.relu(self.fc3(x))\n",
    "#         x = F.relu(self.fc4(x))\n",
    "#         x = F.relu(self.fc5(x))\n",
    "#         x = self.fc6(x)\n",
    "#         return F.log_softmax(x, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1649242283929,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "wlbmCQU2_9y3"
   },
   "outputs": [],
   "source": [
    "# input_size = 300\n",
    "# output_size = 4\n",
    "# hidden_size = 50\n",
    "# num_epochs = 3#testのため回数少なめ\n",
    "# learning_rate = 1e-3\n",
    "# batch_size = 50\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# op = optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# model = Net(input_size, hidden_size, output_size)\n",
    "# log = train_model(dataset_train, dataset_valid, 64, model, CE, optimizer, 20, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1649242283930,
     "user": {
      "displayName": "Tatsuki Okada",
      "userId": "12310138447043973112"
     },
     "user_tz": -540
    },
    "id": "49vIwKz7rCrj"
   },
   "outputs": [],
   "source": [
    "# 参考https://qiita.com/sudamasahiko/items/b54fed1ffe8bb6d48818\n",
    "# https://atmarkit.itmedia.co.jp/ait/articles/2002/06/news025.html\n",
    "# https://recruit.gmo.jp/engineer/jisedai/blog/pytorch_simplenn_to_gan/\n",
    "# https://wonderfuru.com/scheduler/\n",
    "# https://katsura-jp.hatenablog.com/entry/2019/01/30/183501"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNzZMxyrH9phbdx2HlZWZ9t",
   "collapsed_sections": [],
   "mount_file_id": "1NkwxYqvAel8iC4cI6HIy1Qm1pyqPEP7w",
   "name": "NLP_100_8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
