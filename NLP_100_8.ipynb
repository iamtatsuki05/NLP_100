{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP_100_8.ipynb","provenance":[],"mount_file_id":"1NkwxYqvAel8iC4cI6HIy1Qm1pyqPEP7w","authorship_tag":"ABX9TyNGa3ZgbZ8qeqbqg0BZ7hb7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ニューラルネット\n","## 第6章で取り組んだニュース記事のカテゴリ分類を題材として，ニューラルネットワークでカテゴリ分類モデルを実装する．なお，この章ではPyTorch, TensorFlow, Chainerなどの機械学習プラットフォームを活用せよ．\n","\n","\n","\n","####https://nlp100.github.io/ja/ch08.html"],"metadata":{"id":"Mlf0v2adFGzT"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"jBYlYY_Q7o3R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647591624292,"user_tz":-540,"elapsed":11262,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"}},"outputId":"6d27f1eb-6e02-431d-af98-61cdde3125a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# 単語ベクトルの和による特徴量Permalink\n","## 問題50で構築した学習データ，検証データ，評価データを行列・ベクトルに変換したい．例えば，学習データについて，すべての事例xiの特徴ベクトルxiを並べた行列Xと，正解ラベルを並べた行列（ベクトル）Yを作成したい．\n","\n","X=⎛⎝⎜⎜⎜⎜x1x2…xn⎞⎠⎟⎟⎟⎟∈ℝn×d,Y=⎛⎝⎜⎜⎜⎜y1y2…yn⎞⎠⎟⎟⎟⎟∈ℕn\n","ここで，nは学習データの事例数であり，xi∈ℝdとyi∈ℕはそれぞれ，i∈{1,…,n}番目の事例の特徴量ベクトルと正解ラベルを表す． なお，今回は「ビジネス」「科学技術」「エンターテイメント」「健康」の4カテゴリ分類である．ℕ<4で4未満の自然数（0を含む）を表すことにすれば，任意の事例の正解ラベルyiはyi∈ℕ<4で表現できる． 以降では，ラベルの種類数をLで表す（今回の分類タスクではL=4である）．\n","\n","i番目の事例の特徴ベクトルxiは，次式で求める．\n","\n","xi=1Ti∑t=1Tiemb(wi,t)\n","ここで，i番目の事例はTi個の（記事見出しの）単語列(wi,1,wi,2,…,wi,Ti)から構成され，emb(w)∈ℝdは単語wに対応する単語ベクトル（次元数はd）である．すなわち，i番目の事例の記事見出しを，その見出しに含まれる単語のベクトルの平均で表現したものがxiである．今回は単語ベクトルとして，問題60でダウンロードしたものを用いればよい．300次元の単語ベクトルを用いたので，d=300である．\n","\n","i番目の事例のラベルyiは，次のように定義する．\n","\n","yi=⎧⎩⎨⎪⎪0123(記事xiが「ビジネス」カテゴリの場合)(記事xiが「科学技術」カテゴリの場合)(記事xiが「エンターテイメント」カテゴリの場合)(記事xiが「健康」カテゴリの場合)\n","なお，カテゴリ名とラベルの番号が一対一で対応付いていれば，上式の通りの対応付けでなくてもよい．\n","\n","以上の仕様に基づき，以下の行列・ベクトルを作成し，ファイルに保存せよ．\n","\n","学習データの特徴量行列: Xtrain∈ℝNt×d\n","学習データのラベルベクトル: Ytrain∈ℕNt\n","検証データの特徴量行列: Xvalid∈ℝNv×d\n","検証データのラベルベクトル: Yvalid∈ℕNv\n","評価データの特徴量行列: Xtest∈ℝNe×d\n","評価データのラベルベクトル: Ytest∈ℕNe\n","なお，Nt,Nv,Neはそれぞれ，学習データの事例数，検証データの事例数，評価データの事例数である．"],"metadata":{"id":"ap0ufgsdFG2U"}},{"cell_type":"markdown","source":["# 単層ニューラルネットワークによる予測\n","## 問題70で保存した行列を読み込み，学習データについて以下の計算を実行せよ．\n","\n","ŷ 1=softmax(x1W),Ŷ =softmax(X[1:4]W)\n","ただし，softmaxはソフトマックス関数，X[1:4]∈ℝ4×dは特徴ベクトルx1,x2,x3,x4を縦に並べた行列である．\n","\n","X[1:4]=⎛⎝⎜⎜⎜⎜x1x2x3x4⎞⎠⎟⎟⎟⎟\n","行列W∈ℝd×Lは単層ニューラルネットワークの重み行列で，ここではランダムな値で初期化すればよい（問題73以降で学習して求める）．なお，ŷ 1∈ℝLは未学習の行列Wで事例x1を分類したときに，各カテゴリに属する確率を表すベクトルである． 同様に，Ŷ ∈ℝn×Lは，学習データの事例x1,x2,x3,x4について，各カテゴリに属する確率を行列として表現している．\n","\n"],"metadata":{"id":"hLQupFd_FG7y"}},{"cell_type":"markdown","source":["# 損失と勾配の計算Permalink\n","## 学習データの事例x1と事例集合x1,x2,x3,x4に対して，クロスエントロピー損失と，行列Wに対する勾配を計算せよ．なお，ある事例xiに対して損失は次式で計算される．\n","\n","li=−log[事例xiがyiに分類される確率]\n","ただし，事例集合に対するクロスエントロピー損失は，その集合に含まれる各事例の損失の平均とする．"],"metadata":{"id":"qT31R91uFG-w"}},{"cell_type":"markdown","source":["# 確率的勾配降下法による学習\n","## 確率的勾配降下法（SGD: Stochastic Gradient Descent）を用いて，行列Wを学習せよ．なお，学習は適当な基準で終了させればよい（例えば「100エポックで終了」など）．\n","\n"],"metadata":{"id":"VQB9mSC0FHBg"}},{"cell_type":"code","source":[""],"metadata":{"id":"dBS675QJI54t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 正解率の計測Permalink\n","## 問題73で求めた行列を用いて学習データおよび評価データの事例を分類したとき，その正解率をそれぞれ求めよ．"],"metadata":{"id":"m7_iLBR2FHDu"}},{"cell_type":"code","source":[""],"metadata":{"id":"ef6ElOqaI485"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 損失と正解率のプロットPermalink\n","## 問題73のコードを改変し，各エポックのパラメータ更新が完了するたびに，訓練データでの損失，正解率，検証データでの損失，正解率をグラフにプロットし，学習の進捗状況を確認できるようにせよ．"],"metadata":{"id":"6r-LVu0EFHGV"}},{"cell_type":"code","source":[""],"metadata":{"id":"dUWkoGtLI4cQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# チェックポイント\n","## 問題75のコードを改変し，各エポックのパラメータ更新が完了するたびに，チェックポイント（学習途中のパラメータ（重み行列など）の値や最適化アルゴリズムの内部状態）をファイルに書き出せ．\n"],"metadata":{"id":"Rc0r4dkvFHIm"}},{"cell_type":"code","source":[""],"metadata":{"id":"1_lkbSK5I3qI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ミニバッチ化\n","## 問題76のコードを改変し，B事例ごとに損失・勾配を計算し，行列Wの値を更新せよ（ミニバッチ化）．Bの値を1,2,4,8,…と変化させながら，1エポックの学習に要する時間を比較せよ．"],"metadata":{"id":"PJmQqI3PFHLE"}},{"cell_type":"code","source":[""],"metadata":{"id":"kPnqqX1XI1r6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# GPU上での学習\n","## 問題77のコードを改変し，GPU上で学習を実行せよ．"],"metadata":{"id":"-3DmpIYkFHNo"}},{"cell_type":"code","source":[""],"metadata":{"id":"N5udvkcHI1I1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 多層ニューラルネットワーク\n","## 問題78のコードを改変し，バイアス項の導入や多層化など，ニューラルネットワークの形状を変更しながら，高性能なカテゴリ分類器を構築せよ．"],"metadata":{"id":"LonpamKPFHQA"}},{"cell_type":"code","source":[""],"metadata":{"id":"_RrLo55OI0Y_"},"execution_count":null,"outputs":[]}]}