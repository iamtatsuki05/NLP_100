{"cells":[{"cell_type":"markdown","metadata":{"id":"wy4FSmYcJIwK"},"source":["# RNN, CNN\n"]},{"cell_type":"markdown","source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/iamtatsuki05/NLP_100/blob/NLP_100_9/NLP_100_3.ipynb)"],"metadata":{"id":"67ddAau-HU9t"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17534,"status":"ok","timestamp":1648147589916,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"},"user_tz":-540},"id":"jBYlYY_Q7o3R","outputId":"da2e4994-f197-42c0-a9d0-1743e7cbceed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"CJIjsxfDJcfv"},"source":["# ID番号への変換\n","## 問題51で構築した学習データ中の単語にユニークなID番号を付与したい．学習データ中で最も頻出する単語に1，2番目に頻出する単語に2，……といった方法で，学習データ中で2回以上出現する単語にID番号を付与せよ．そして，与えられた単語列に対して，ID番号の列を返す関数を実装せよ．ただし，出現頻度が2回未満の単語のID番号はすべて0とせよ"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5879,"status":"ok","timestamp":1648147595790,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"},"user_tz":-540},"id":"03YyU3nTKzhG","outputId":"c63cc7a9-e47a-48a6-9d76-1d2d2b9b7211"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-03-24 18:46:29--  https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip\n","Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n","Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 29224203 (28M) [application/x-httpd-php]\n","Saving to: ‘NewsAggregatorDataset.zip’\n","\n","NewsAggregatorDatas 100%[===================>]  27.87M  25.2MB/s    in 1.1s    \n","\n","2022-03-24 18:46:31 (25.2 MB/s) - ‘NewsAggregatorDataset.zip’ saved [29224203/29224203]\n","\n","Archive:  NewsAggregatorDataset.zip\n","  inflating: 2pageSessions.csv       \n","   creating: __MACOSX/\n","  inflating: __MACOSX/._2pageSessions.csv  \n","  inflating: newsCorpora.csv         \n","  inflating: __MACOSX/._newsCorpora.csv  \n","  inflating: readme.txt              \n","  inflating: __MACOSX/._readme.txt   \n"]},{"output_type":"execute_result","data":{"text/plain":["{'to': 1,\n"," 's': 2,\n"," 'in': 3,\n"," 'UPDATE': 4,\n"," 'on': 5,\n"," 'as': 6,\n"," 'US': 7,\n"," 'The': 8,\n"," 'of': 9,\n"," 'for': 10,\n"," '1': 11,\n"," 'To': 12,\n"," '2': 13,\n"," 'the': 14,\n"," 'and': 15,\n"," 'In': 16,\n"," 'Of': 17,\n"," 'a': 18,\n"," 'at': 19,\n"," 'A': 20,\n"," 'With': 21,\n"," 'Is': 22,\n"," 'For': 23,\n"," 'And': 24,\n"," 'with': 25,\n"," 'after': 26,\n"," 'New': 27,\n"," '3': 28,\n"," 'Kardashian': 29,\n"," 'China': 30,\n"," 'up': 31,\n"," 'On': 32,\n"," 'Kim': 33,\n"," 'by': 34,\n"," 'says': 35,\n"," 'is': 36,\n"," 'After': 37,\n"," 'At': 38,\n"," 'ECB': 39,\n"," 'STOCKS': 40,\n"," 'From': 41,\n"," 't': 42,\n"," 'Fed': 43,\n"," 'from': 44,\n"," '4': 45,\n"," 'new': 46,\n"," 'Cyrus': 47,\n"," 'Miley': 48,\n"," 'It': 49,\n"," 'her': 50,\n"," 'Wall': 51,\n"," 'Says': 52,\n"," 'FOREX': 53,\n"," 'shares': 54,\n"," '5': 55,\n"," 'CEO': 56,\n"," 'Dollar': 57,\n"," 'First': 58,\n"," 'data': 59,\n"," 'Google': 60,\n"," 'West': 61,\n"," 'over': 62,\n"," 'she': 63,\n"," 'About': 64,\n"," 'St': 65,\n"," 'May': 66,\n"," 'S': 67,\n"," 'Euro': 68,\n"," 'Will': 69,\n"," 'You': 70,\n"," 'Ukraine': 71,\n"," 'More': 72,\n"," 'Chris': 73,\n"," 'As': 74,\n"," 'bln': 75,\n"," '2014': 76,\n"," 'Kanye': 77,\n"," 'Be': 78,\n"," 'Up': 79,\n"," 'Apple': 80,\n"," 'Star': 81,\n"," 'Over': 82,\n"," 'Stocks': 83,\n"," 'Justin': 84,\n"," 'off': 85,\n"," 'Bieber': 86,\n"," 'I': 87,\n"," 'be': 88,\n"," 'euro': 89,\n"," 'Billion': 90,\n"," 'UK': 91,\n"," 'but': 92,\n"," 'Are': 93,\n"," 'GM': 94,\n"," 'out': 95,\n"," 'GLOBAL': 96,\n"," 'Bank': 97,\n"," 'it': 98,\n"," 'How': 99,\n"," 'That': 100,\n"," 'deal': 101,\n"," 'RPT': 102,\n"," 'Day': 103,\n"," 'Yellen': 104,\n"," 'profit': 105,\n"," '7': 106,\n"," 'sales': 107,\n"," 'Time': 108,\n"," '6': 109,\n"," 'Not': 110,\n"," 'Her': 111,\n"," 'Twitter': 112,\n"," 'P': 113,\n"," 'pct': 114,\n"," 'Game': 115,\n"," 'Gold': 116,\n"," 'high': 117,\n"," 'not': 118,\n"," 'growth': 119,\n"," 'Out': 120,\n"," 'first': 121,\n"," 'rise': 122,\n"," 'MARKETS': 123,\n"," 'What': 124,\n"," 'One': 125,\n"," 'CORRECTED': 126,\n"," 'American': 127,\n"," 'year': 128,\n"," 'Beyonce': 129,\n"," 'are': 130,\n"," 'more': 131,\n"," 'Home': 132,\n"," 'that': 133,\n"," 'he': 134,\n"," 'IPO': 135,\n"," 'Sales': 136,\n"," 'Lohan': 137,\n"," 'Facebook': 138,\n"," 'near': 139,\n"," 'T': 140,\n"," 'buy': 141,\n"," 'York': 142,\n"," 'Amazon': 143,\n"," 'This': 144,\n"," 'High': 145,\n"," 'Lindsay': 146,\n"," 'higher': 147,\n"," 'By': 148,\n"," 'Paul': 149,\n"," 'Deal': 150,\n"," 'Million': 151,\n"," 'No': 152,\n"," 'month': 153,\n"," 'down': 154,\n"," 'George': 155,\n"," 'will': 156,\n"," 'Video': 157,\n"," 'Thrones': 158,\n"," 'America': 159,\n"," 'his': 160,\n"," 'stocks': 161,\n"," 'Year': 162,\n"," 'Your': 163,\n"," 'Draghi': 164,\n"," 'Jay': 165,\n"," 'Most': 166,\n"," 'day': 167,\n"," 'set': 168,\n"," 'low': 169,\n"," 'Why': 170,\n"," 'rises': 171,\n"," 'could': 172,\n"," 'inflation': 173,\n"," 'Movie': 174,\n"," 'Russia': 175,\n"," 'fall': 176,\n"," 'about': 177,\n"," 'Selena': 178,\n"," 'TV': 179,\n"," 'Rise': 180,\n"," 'reveals': 181,\n"," 'was': 182,\n"," 'European': 183,\n"," 'oil': 184,\n"," '10': 185,\n"," 'Gomez': 186,\n"," 'Michael': 187,\n"," 'June': 188,\n"," 'Than': 189,\n"," 'week': 190,\n"," 'Report': 191,\n"," 'Iraq': 192,\n"," 'We': 193,\n"," 'WRAPUP': 194,\n"," 'Z': 195,\n"," 'James': 196,\n"," 'Men': 197,\n"," 'BNP': 198,\n"," 'has': 199,\n"," 'Europe': 200,\n"," 'Ebola': 201,\n"," '8': 202,\n"," '9': 203,\n"," 'World': 204,\n"," 'His': 205,\n"," 'Fitch': 206,\n"," 'Before': 207,\n"," 'Can': 208,\n"," 'All': 209,\n"," 'Shares': 210,\n"," 'Show': 211,\n"," '500': 212,\n"," 'Week': 213,\n"," 'But': 214,\n"," 'gains': 215,\n"," 'L': 216,\n"," 'shows': 217,\n"," 'ahead': 218,\n"," 'Profit': 219,\n"," 'Big': 220,\n"," 'Man': 221,\n"," 'Scott': 222,\n"," 'rate': 223,\n"," 'Alibaba': 224,\n"," 'into': 225,\n"," 'Awards': 226,\n"," 'hit': 227,\n"," 'Amid': 228,\n"," 'Have': 229,\n"," 'Said': 230,\n"," 'Japan': 231,\n"," 'Was': 232,\n"," 'Get': 233,\n"," 'Drop': 234,\n"," 'Martin': 235,\n"," 'may': 236,\n"," 'wedding': 237,\n"," 'Has': 238,\n"," 'record': 239,\n"," 'against': 240,\n"," 'Outlook': 241,\n"," 'falls': 242,\n"," 'Jennifer': 243,\n"," 'PRECIOUS': 244,\n"," 'Month': 245,\n"," 'Wars': 246,\n"," 'Two': 247,\n"," 'Met': 248,\n"," 'Could': 249,\n"," 'prices': 250,\n"," 'Low': 251,\n"," 'North': 252,\n"," 'Pfizer': 253,\n"," 'lower': 254,\n"," 'Street': 255,\n"," 'than': 256,\n"," 'Top': 257,\n"," 'mln': 258,\n"," 'Samsung': 259,\n"," 'Pay': 260,\n"," 'Just': 261,\n"," 'jobs': 262,\n"," 'sees': 263,\n"," 'Season': 264,\n"," 'Mobile': 265,\n"," 'have': 266,\n"," 'Into': 267,\n"," 'Microsoft': 268,\n"," 'Hong': 269,\n"," 'Kong': 270,\n"," 'Its': 271,\n"," 'Since': 272,\n"," 'Years': 273,\n"," 'revenue': 274,\n"," 'Futures': 275,\n"," 'Rate': 276,\n"," 'German': 277,\n"," 'Obama': 278,\n"," 'Court': 279,\n"," 'before': 280,\n"," 'show': 281,\n"," 'Off': 282,\n"," 'She': 283,\n"," 'Falls': 284,\n"," 'Oil': 285,\n"," 'Music': 286,\n"," 'Credit': 287,\n"," 'zone': 288,\n"," 'Death': 289,\n"," 'Who': 290,\n"," 'Film': 291,\n"," 'hits': 292,\n"," 'Buy': 293,\n"," 'Health': 294,\n"," 'two': 295,\n"," 'dollar': 296,\n"," 'Data': 297,\n"," 'Estimates': 298,\n"," 'Robert': 299,\n"," 'REFILE': 300,\n"," 'cuts': 301,\n"," 'Wedding': 302,\n"," 'Study': 303,\n"," 'Williams': 304,\n"," 'Jagger': 305,\n"," 'French': 306,\n"," 'Record': 307,\n"," 'bond': 308,\n"," 'Gwyneth': 309,\n"," 'Zac': 310,\n"," 'top': 311,\n"," 'drug': 312,\n"," 'Climate': 313,\n"," 'Second': 314,\n"," 'Efron': 315,\n"," 'April': 316,\n"," 'Jackson': 317,\n"," 'Change': 318,\n"," 'star': 319,\n"," 'Shows': 320,\n"," 'Brown': 321,\n"," 'who': 322,\n"," 'Emma': 323,\n"," 'Jessica': 324,\n"," 'Don': 325,\n"," 'no': 326,\n"," 'Robin': 327,\n"," 'takes': 328,\n"," 'flat': 329,\n"," 'market': 330,\n"," 'Paltrow': 331,\n"," 'AstraZeneca': 332,\n"," 'can': 333,\n"," 'business': 334,\n"," 'Mick': 335,\n"," 'Jolie': 336,\n"," 'talks': 337,\n"," 'Mother': 338,\n"," 'Episode': 339,\n"," 'Fox': 340,\n"," 'Best': 341,\n"," 'Angelina': 342,\n"," 'Clooney': 343,\n"," 'Against': 344,\n"," 'Ford': 345,\n"," 'Bonds': 346,\n"," 'Set': 347,\n"," 'com': 348,\n"," 'Obamacare': 349,\n"," 'SNAPSHOT': 350,\n"," 'Rises': 351,\n"," 'bid': 352,\n"," 'court': 353,\n"," 'an': 354,\n"," 'People': 355,\n"," 'pay': 356,\n"," 'Netflix': 357,\n"," 'report': 358,\n"," 'back': 359,\n"," 'Affirms': 360,\n"," 'Market': 361,\n"," 'Growth': 362,\n"," 'Gain': 363,\n"," 'March': 364,\n"," 'Dies': 365,\n"," 'source': 366,\n"," 'Stars': 367,\n"," 'billion': 368,\n"," 'Yen': 369,\n"," 'White': 370,\n"," 'Walker': 371,\n"," 'Argentina': 372,\n"," 'Still': 373,\n"," 'take': 374,\n"," 'Gains': 375,\n"," 'seen': 376,\n"," 'My': 377,\n"," 'all': 378,\n"," 'House': 379,\n"," 'ends': 380,\n"," '50': 381,\n"," 'FDA': 382,\n"," 'Seen': 383,\n"," 'Economy': 384,\n"," 'Khloe': 385,\n"," 'Love': 386,\n"," 'gas': 387,\n"," 'Down': 388,\n"," 'percent': 389,\n"," 'million': 390,\n"," 'Chinese': 391,\n"," 'gets': 392,\n"," 'Comcast': 393,\n"," 'banks': 394,\n"," 'Jenner': 395,\n"," 'EU': 396,\n"," 'Review': 397,\n"," 'Now': 398,\n"," 'Real': 399,\n"," 'Box': 400,\n"," 'they': 401,\n"," 'Alstom': 402,\n"," 'offer': 403,\n"," 'Johnny': 404,\n"," 'Air': 405,\n"," 'Fans': 406,\n"," 'Internet': 407,\n"," '20': 408,\n"," 'France': 409,\n"," 'Drops': 410,\n"," 'time': 411,\n"," 'case': 412,\n"," 'Talks': 413,\n"," 'An': 414,\n"," 'yields': 415,\n"," 'their': 416,\n"," 'make': 417,\n"," 'BOJ': 418,\n"," 'Asian': 419,\n"," 'Watch': 420,\n"," 'you': 421,\n"," 'Asia': 422,\n"," 'Ryan': 423,\n"," 'Plan': 424,\n"," 'claims': 425,\n"," 'Spider': 426,\n"," 'Office': 427,\n"," 'David': 428,\n"," 'India': 429,\n"," 'Tour': 430,\n"," '100': 431,\n"," 'quarter': 432,\n"," 'loss': 433,\n"," 'end': 434,\n"," 'Brent': 435,\n"," 'Morgan': 436,\n"," 'Taylor': 437,\n"," 'years': 438,\n"," 'Stone': 439,\n"," 'Thicke': 440,\n"," 'strong': 441,\n"," 'since': 442,\n"," 'Tesla': 443,\n"," 'Make': 444,\n"," 'cut': 445,\n"," 'IMF': 446,\n"," 'home': 447,\n"," 'Some': 448,\n"," 'Forecast': 449,\n"," 'Trailer': 450,\n"," 'Valeant': 451,\n"," 'He': 452,\n"," 'Festival': 453,\n"," 'Won': 454,\n"," 'Target': 455,\n"," 'Inflation': 456,\n"," 'Harris': 457,\n"," 'debt': 458,\n"," 'maker': 459,\n"," 'firm': 460,\n"," 'Voice': 461,\n"," 'Noah': 462,\n"," 'bank': 463,\n"," 'Cancer': 464,\n"," 'Back': 465,\n"," 'U': 466,\n"," 'slips': 467,\n"," 'its': 468,\n"," 'Allergan': 469,\n"," 'Know': 470,\n"," 'John': 471,\n"," '2015': 472,\n"," 'open': 473,\n"," 'Kate': 474,\n"," 'So': 475,\n"," 'E': 476,\n"," 'MERS': 477,\n"," 'rates': 478,\n"," 'economy': 479,\n"," 'Sees': 480,\n"," 'earnings': 481,\n"," 'Cannes': 482,\n"," 'AT': 483,\n"," 'Wren': 484,\n"," 'Here': 485,\n"," 'Risk': 486,\n"," 'Banks': 487,\n"," 'drops': 488,\n"," 'makes': 489,\n"," 'O': 490,\n"," 'Young': 491,\n"," 'Case': 492,\n"," 'office': 493,\n"," 'study': 494,\n"," 'Baby': 495,\n"," 'AP': 496,\n"," '—': 497,\n"," 'UN': 498,\n"," 'Depp': 499,\n"," 'Play': 500,\n"," 'dies': 501,\n"," 'Ex': 502,\n"," 'Dead': 503,\n"," 'Fall': 504,\n"," 'Swift': 505,\n"," 'still': 506,\n"," 'Life': 507,\n"," 'News': 508,\n"," 'Sex': 509,\n"," 'just': 510,\n"," 'one': 511,\n"," 'Barclays': 512,\n"," 'drop': 513,\n"," 'comments': 514,\n"," 'Good': 515,\n"," 'Rates': 516,\n"," 'Andrew': 517,\n"," 'Things': 518,\n"," 'Us': 519,\n"," 'Five': 520,\n"," 'McDonald': 521,\n"," 'opens': 522,\n"," 'sell': 523,\n"," 'Gala': 524,\n"," 'Three': 525,\n"," 'policy': 526,\n"," 'Cut': 527,\n"," 'Prices': 528,\n"," 'Kids': 529,\n"," 'video': 530,\n"," 'this': 531,\n"," 'Garfield': 532,\n"," 'July': 533,\n"," 'Simpson': 534,\n"," 'Like': 535,\n"," 'Mad': 536,\n"," 'Warner': 537,\n"," 'face': 538,\n"," 'Lana': 539,\n"," 'MTV': 540,\n"," 'Pregnant': 541,\n"," 'raises': 542,\n"," 'Nasdaq': 543,\n"," 'South': 544,\n"," 'End': 545,\n"," 'Calls': 546,\n"," 'Lady': 547,\n"," 'Seth': 548,\n"," 'results': 549,\n"," 'Fight': 550,\n"," 'Even': 551,\n"," 'box': 552,\n"," 'Franco': 553,\n"," 'Gets': 554,\n"," 'Family': 555,\n"," 'cars': 556,\n"," 'Nick': 557,\n"," 'again': 558,\n"," 'Cast': 559,\n"," 'probe': 560,\n"," 'Beats': 561,\n"," 'risk': 562,\n"," 'man': 563,\n"," 'Del': 564,\n"," 'Rey': 565,\n"," 'Chrysler': 566,\n"," 'Again': 567,\n"," 'Pharrell': 568,\n"," 're': 569,\n"," 'dress': 570,\n"," 'rally': 571,\n"," 'Another': 572,\n"," 'Smith': 573,\n"," 'M': 574,\n"," 'Stable': 575,\n"," 'Reveals': 576,\n"," 'Singer': 577,\n"," 'They': 578,\n"," 'Cuts': 579,\n"," 'hike': 580,\n"," 'Brad': 581,\n"," 'View': 582,\n"," 'Jr': 583,\n"," 'When': 584,\n"," 'concerns': 585,\n"," 'found': 586,\n"," 'boost': 587,\n"," 'plans': 588,\n"," 'Rolling': 589,\n"," 'vs': 590,\n"," 'global': 591,\n"," 'Tax': 592,\n"," 'Director': 593,\n"," 'Takes': 594,\n"," 'life': 595,\n"," 'second': 596,\n"," 'London': 597,\n"," 'Australia': 598,\n"," 'being': 599,\n"," 'Bad': 600,\n"," 'estimates': 601,\n"," 'six': 602,\n"," 'Global': 603,\n"," 'Solange': 604,\n"," 'eyes': 605,\n"," 'weak': 606,\n"," 'Stanley': 607,\n"," 'Pitt': 608,\n"," 'debut': 609,\n"," 'outlook': 610,\n"," 'Do': 611,\n"," 'GRAINS': 612,\n"," 'steady': 613,\n"," 'Earth': 614,\n"," 'Yahoo': 615,\n"," 'Miranda': 616,\n"," 'During': 617,\n"," 'Future': 618,\n"," 'Virus': 619,\n"," 'VII': 620,\n"," 'Disney': 621,\n"," 'Photo': 622,\n"," 'holds': 623,\n"," 'tour': 624,\n"," 'Live': 625,\n"," 'Ahead': 626,\n"," 'bonds': 627,\n"," 'Role': 628,\n"," 'Months': 629,\n"," 'baby': 630,\n"," 'Cars': 631,\n"," 'J': 632,\n"," 'California': 633,\n"," 'Way': 634,\n"," 'Decline': 635,\n"," 'Loss': 636,\n"," 'sources': 637,\n"," 'Should': 638,\n"," 'Shire': 639,\n"," 'Go': 640,\n"," '12': 641,\n"," 'Album': 642,\n"," 'Last': 643,\n"," 'trading': 644,\n"," 'Red': 645,\n"," 'Canada': 646,\n"," 'sex': 647,\n"," 'Hollywood': 648,\n"," 'Too': 649,\n"," 'lows': 650,\n"," 'Rogen': 651,\n"," 'Africa': 652,\n"," 'Short': 653,\n"," 'world': 654,\n"," 'warns': 655,\n"," 'during': 656,\n"," 'Demand': 657,\n"," 'Neil': 658,\n"," 'Lena': 659,\n"," 'Dunham': 660,\n"," 'your': 661,\n"," 'or': 662,\n"," 'Women': 663,\n"," 'GE': 664,\n"," 'if': 665,\n"," 'gain': 666,\n"," 'red': 667,\n"," 'Near': 668,\n"," 'Paribas': 669,\n"," 'Paris': 670,\n"," 'Shia': 671,\n"," 'Space': 672,\n"," 'Fiat': 673,\n"," 'Christina': 674,\n"," 'Former': 675,\n"," 'big': 676,\n"," 'King': 677,\n"," 'Rolf': 678,\n"," 'Boeing': 679,\n"," 'fans': 680,\n"," 'Gaga': 681,\n"," 'investors': 682,\n"," 'wants': 683,\n"," 'Half': 684,\n"," 'Bid': 685,\n"," 'Face': 686,\n"," 'Party': 687,\n"," 'posts': 688,\n"," 'Gay': 689,\n"," 'Take': 690,\n"," 'See': 691,\n"," 'Did': 692,\n"," 'Ice': 693,\n"," 'Being': 694,\n"," 'Carney': 695,\n"," 'death': 696,\n"," 'close': 697,\n"," 'Apparel': 698,\n"," 'car': 699,\n"," 'McCarthy': 700,\n"," 'wins': 701,\n"," 'Jump': 702,\n"," 'Really': 703,\n"," 'Stones': 704,\n"," 'Captain': 705,\n"," 'List': 706,\n"," 'Heart': 707,\n"," 'forecast': 708,\n"," 'Claims': 709,\n"," 'm': 710,\n"," 'Lea': 711,\n"," 'Cover': 712,\n"," 'Dow': 713,\n"," 'losses': 714,\n"," 'Car': 715,\n"," 'while': 716,\n"," 'Makes': 717,\n"," 'stake': 718,\n"," 'WSJ': 719,\n"," 'Amazing': 720,\n"," 'below': 721,\n"," 'steps': 722,\n"," 'Seeks': 723,\n"," 'Toyota': 724,\n"," 'NY': 725,\n"," 'edge': 726,\n"," 'Wants': 727,\n"," 'Glass': 728,\n"," 'HBO': 729,\n"," 'Gas': 730,\n"," 'plan': 731,\n"," 'Suisse': 732,\n"," 'Bryan': 733,\n"," 'possible': 734,\n"," 'film': 735,\n"," 'supply': 736,\n"," 'Arrested': 737,\n"," 'settle': 738,\n"," 'quarterly': 739,\n"," 'Pound': 740,\n"," 'Woman': 741,\n"," 'Kristen': 742,\n"," 'next': 743,\n"," 'cancer': 744,\n"," 'demand': 745,\n"," 'despite': 746,\n"," 'Biggest': 747,\n"," 'Rally': 748,\n"," 'Russian': 749,\n"," 'VIDEO': 750,\n"," 'Russell': 751,\n"," 'Increase': 752,\n"," 'Look': 753,\n"," 'Bond': 754,\n"," 'Bachelorette': 755,\n"," 'Bell': 756,\n"," 'under': 757,\n"," 'nearly': 758,\n"," 'Making': 759,\n"," 'Food': 760,\n"," 'Michele': 761,\n"," 'names': 762,\n"," 'Probe': 763,\n"," 'raise': 764,\n"," '14': 765,\n"," 'beats': 766,\n"," 'Lawsuit': 767,\n"," 'Broadway': 768,\n"," 'Tribute': 769,\n"," 'Treasury': 770,\n"," 'Jobs': 771,\n"," 'help': 772,\n"," 'Prince': 773,\n"," 'fears': 774,\n"," 'Dancing': 775,\n"," 'Black': 776,\n"," 'recall': 777,\n"," 'e': 778,\n"," 'like': 779,\n"," 'Other': 780,\n"," 'mortgage': 781,\n"," 'goes': 782,\n"," 'ex': 783,\n"," 'Test': 784,\n"," 'Goldman': 785,\n"," 'sister': 786,\n"," 'rules': 787,\n"," '13': 788,\n"," 'Actor': 789,\n"," '30': 790,\n"," 'Mars': 791,\n"," 'people': 792,\n"," 'Four': 793,\n"," 'unit': 794,\n"," 'Tech': 795,\n"," 'Rihanna': 796,\n"," 'dip': 797,\n"," 'yen': 798,\n"," 'Americans': 799,\n"," 'Aereo': 800,\n"," 'health': 801,\n"," 'Jimmy': 802,\n"," 'Critics': 803,\n"," 'Stock': 804,\n"," 'plane': 805,\n"," 'merger': 806,\n"," 'Tops': 807,\n"," 'Higher': 808,\n"," 'DirecTV': 809,\n"," 'now': 810,\n"," 'Mila': 811,\n"," 'Kunis': 812,\n"," 'Girls': 813,\n"," 'away': 814,\n"," 'birthday': 815,\n"," 'De': 816,\n"," 'sale': 817,\n"," 'Business': 818,\n"," 'early': 819,\n"," 'Under': 820,\n"," 'Money': 821,\n"," 'Drug': 822,\n"," 'lawsuit': 823,\n"," 'amid': 824,\n"," 'Harrison': 825,\n"," 'Demi': 826,\n"," 'Lovato': 827,\n"," 'Swiss': 828,\n"," 'Tv': 829,\n"," 'Rules': 830,\n"," 'Cable': 831,\n"," 'jumps': 832,\n"," 'AbbVie': 833,\n"," 'Transformers': 834,\n"," 'expected': 835,\n"," 'Yields': 836,\n"," 'Long': 837,\n"," 'Debt': 838,\n"," 'Posts': 839,\n"," 'company': 840,\n"," 'little': 841,\n"," 'Opens': 842,\n"," 'Michelle': 843,\n"," 'premiere': 844,\n"," 'BofA': 845,\n"," 'Full': 846,\n"," 'Premiere': 847,\n"," 'Child': 848,\n"," 'Wife': 849,\n"," 'Company': 850,\n"," 'costs': 851,\n"," 'Finds': 852,\n"," 'gown': 853,\n"," 'PMI': 854,\n"," 'C': 855,\n"," 'economic': 856,\n"," 'action': 857,\n"," 'Washington': 858,\n"," 'Neighbors': 859,\n"," 'files': 860,\n"," 'Little': 861,\n"," 'Offer': 862,\n"," 'Energy': 863,\n"," 'Montana': 864,\n"," 'edges': 865,\n"," 'above': 866,\n"," 'FCC': 867,\n"," 'Ben': 868,\n"," 'Challenge': 869,\n"," 'Spanish': 870,\n"," 'auto': 871,\n"," 'Investors': 872,\n"," 'Kendall': 873,\n"," 'Instagram': 874,\n"," 'split': 875,\n"," 'Their': 876,\n"," 'Plans': 877,\n"," 'crisis': 878,\n"," 'President': 879,\n"," '15': 880,\n"," 'o': 881,\n"," 'family': 882,\n"," 'Sequel': 883,\n"," 'Push': 884,\n"," 'Times': 885,\n"," 'Or': 886,\n"," 'Johnson': 887,\n"," 'Our': 888,\n"," 'Need': 889,\n"," 'Lewis': 890,\n"," 'party': 891,\n"," 'black': 892,\n"," 'chief': 893,\n"," 'Canadian': 894,\n"," 'Recall': 895,\n"," 'British': 896,\n"," 'Want': 897,\n"," 'half': 898,\n"," 'Getting': 899,\n"," 'Supreme': 900,\n"," 'daughter': 901,\n"," 'Raises': 902,\n"," 'heart': 903,\n"," '22': 904,\n"," 'Manufacturing': 905,\n"," 'If': 906,\n"," 'easing': 907,\n"," 'GDP': 908,\n"," 'Close': 909,\n"," 'tax': 910,\n"," 'Next': 911,\n"," 'Joins': 912,\n"," 'look': 913,\n"," 'Kourtney': 914,\n"," 'Earnings': 915,\n"," 'fight': 916,\n"," 'Lopez': 917,\n"," 'Ban': 918,\n"," 'Malaysia': 919,\n"," 'start': 920,\n"," 'Policy': 921,\n"," 'Bill': 922,\n"," 'Treasuries': 923,\n"," 'guilty': 924,\n"," 'hopes': 925,\n"," 'crude': 926,\n"," 'tops': 927,\n"," 'Six': 928,\n"," 'Corn': 929,\n"," '24': 930,\n"," 'Quarter': 931,\n"," 'Libya': 932,\n"," 'Leads': 933,\n"," 'use': 934,\n"," 'Factors': 935,\n"," 'best': 936,\n"," 'Nyong': 937,\n"," 'LaBeouf': 938,\n"," 'reports': 939,\n"," 'Bets': 940,\n"," 'Idol': 941,\n"," 'long': 942,\n"," '11': 943,\n"," 'Rob': 944,\n"," 'Finale': 945,\n"," 'Birthday': 946,\n"," 'virus': 947,\n"," 'capital': 948,\n"," 'Deutsche': 949,\n"," 'Anti': 950,\n"," 'dips': 951,\n"," 'Behind': 952,\n"," 'Old': 953,\n"," 'Perry': 954,\n"," 'Cameron': 955,\n"," 'call': 956,\n"," 'say': 957,\n"," 'Recap': 958,\n"," 'Mark': 959,\n"," 'had': 960,\n"," 'Airlines': 961,\n"," 'Candy': 962,\n"," 'Index': 963,\n"," 'missing': 964,\n"," 'Fast': 965,\n"," 'Trading': 966,\n"," 'Maker': 967,\n"," 'Morning': 968,\n"," 'slightly': 969,\n"," 'JPMorgan': 970,\n"," 'Sir': 971,\n"," 'Fire': 972,\n"," 'Merger': 973,\n"," 'Dark': 974,\n"," 'Summer': 975,\n"," 'dead': 976,\n"," 'news': 977,\n"," 'Gosling': 978,\n"," 'test': 979,\n"," 'official': 980,\n"," 'so': 981,\n"," 'Vietnam': 982,\n"," 'Hemsworth': 983,\n"," 'Jenny': 984,\n"," 'yr': 985,\n"," 'CDC': 986,\n"," 'Coachella': 987,\n"," 'Children': 988,\n"," 'Help': 989,\n"," 'Lupita': 990,\n"," 'air': 991,\n"," 'Service': 992,\n"," 'Indian': 993,\n"," 'live': 994,\n"," 'firms': 995,\n"," 'price': 996,\n"," 'Ackman': 997,\n"," 'Advance': 998,\n"," 'Power': 999,\n"," 'joins': 1000,\n"," ...}"]},"metadata":{},"execution_count":2}],"source":["#50,51をもう一度\n","!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip\n","!unzip NewsAggregatorDataset.zip\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","df = pd.read_csv('/content/newsCorpora.csv' , header=None , sep='\\t' , names=['ID' , 'TITLE' , 'URL' , 'PUBLISHER' , 'CATEGORY' , 'STORY' , 'HOSTNAME' , 'TIMESTAMP'])\n","\n","# データの抽出\n","df = df.loc[df['PUBLISHER'].isin(['Reuters' , 'Huffington Post' , 'Businessweek' , 'Contactmusic.com' , 'Daily Mail']) , ['TITLE' , 'CATEGORY']]\n","\n","# データの分割\n","train, valid_test = train_test_split(df , test_size = 0.2 , shuffle = True , random_state = 42 , stratify = df['CATEGORY'])\n","valid, test = train_test_split(valid_test , test_size = 0.5 , shuffle = True , random_state = 42 , stratify = valid_test['CATEGORY'])\n","train.reset_index(drop=True , inplace = True)\n","valid.reset_index(drop=True , inplace = True)\n","test.reset_index(drop=True , inplace = True)\n","\n","from collections import defaultdict\n","import string\n","\n","d = defaultdict(int)\n","table = str.maketrans(string.punctuation , ' '*len(string.punctuation))#記号処理\n","for text in train['TITLE']:\n","  for word in text.translate(table).split():\n","    d[word] += 1\n","d = sorted(d.items() , key=lambda x:x[1] , reverse=True)#sort\n","\n","word_id = {word: idx + 1 for idx , (word , num) in enumerate(d) if num > 1}#辞書\n","word_id"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"_YJxuPDht3Zv","executionInfo":{"status":"ok","timestamp":1648147600847,"user_tz":-540,"elapsed":5068,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"}}},"outputs":[],"source":["import torch\n","#テキスト修正\n","def tokenizer(text , word2id=word_id , unk = 0):\n","  table = str.maketrans(string.punctuation , ' '*len(string.punctuation))\n","  return [word2id.get(word , unk) for word in text.translate(table).split()]"]},{"cell_type":"markdown","metadata":{"id":"RUHR6GfrJcia"},"source":["# RNNによる予測\n","## ID番号で表現された単語列x=(x1,x2,…,xT)がある．ただし，Tは単語列の長さ，xt∈ℝVは単語のID番号のone-hot表記である（Vは単語の総数である）．再帰型ニューラルネットワーク（RNN: Recurrent Neural Network）を用い，単語列xからカテゴリyを予測するモデルとして，次式を実装せよ．\n","\n","h→0=0,h→t=RNN−→−−(emb(xt),h→t−1),y=softmax(W(yh)h→T+b(y))\n","ただし，emb(x)∈ℝdwは単語埋め込み（単語のone-hot表記から単語ベクトルに変換する関数），h→t∈ℝdhは時刻tの隠れ状態ベクトル，RNN−→−−(x,h)は入力xと前時刻の隠れ状態hから次状態を計算するRNNユニット，W(yh)∈ℝL×dhは隠れ状態ベクトルからカテゴリを予測するための行列，b(y)∈ℝLはバイアス項である（dw,dh,Lはそれぞれ，単語埋め込みの次元数，隠れ状態ベクトルの次元数，ラベル数である）．RNNユニットRNN−→−−(x,h)には様々な構成が考えられるが，典型例として次式が挙げられる．\n","\n","RNN−→−−(x,h)=g(W(hx)x+W(hh)h+b(h))\n","ただし，W(hx)∈ℝdh×dw，W(hh)∈ℝdh×dh,b(h)∈ℝdhはRNNユニットのパラメータ，gは活性化関数（例えばtanhやReLUなど）である．\n","\n","なお，この問題ではパラメータの学習を行わず，ランダムに初期化されたパラメータでyを計算するだけでよい．次元数などのハイパーパラメータは，dw=300,dh=50など，適当な値に設定せよ（以降の問題でも同様である）．"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"HZAWporJ92Nc","executionInfo":{"status":"ok","timestamp":1648147600847,"user_tz":-540,"elapsed":17,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"}}},"outputs":[],"source":["# ，dw=300,dh=50"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"cmQohg-guRUT","executionInfo":{"status":"ok","timestamp":1648147600847,"user_tz":-540,"elapsed":16,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"}}},"outputs":[],"source":["import torch\n","from torch import nn\n","torch.manual_seed(42)\n","\n","class RNN(nn.Module):\n","  def __init__(self , vocab_size , emb_size , padding_idx , output_size , hidden_size):\n","    super().__init__()\n","    self.hidden_size = hidden_size\n","    self.emb = nn.Embedding(vocab_size , emb_size , padding_idx=padding_idx)\n","    self.rnn = nn.RNN(emb_size , hidden_size , nonlinearity='relu' , batch_first=True)\n","    self.fc = nn.Linear(hidden_size , output_size)\n","    \n","  def forward(self, x):\n","    self.batch_size = x.size()[0]\n","    hidden = self.init_hidden()\n","    emb = self.emb(x)\n","    out, hidden = self.rnn(emb , hidden)\n","    out = self.fc(out[: , -1 , :])\n","    return out\n","    \n","  def init_hidden(self):\n","    hidden = torch.zeros(1, self.batch_size , self.hidden_size)\n","    return hidden"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"UDZqdi2OuUjb","executionInfo":{"status":"ok","timestamp":1648147600848,"user_tz":-540,"elapsed":17,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"}}},"outputs":[],"source":["from torch.utils.data import Dataset\n","\n","class CreateDataset(Dataset):\n","  def __init__(self , X , y , tokenizer):\n","    self.X = X\n","    self.y = y\n","    self.tokenizer = tokenizer\n","\n","  def __len__(self):\n","    return len(self.y)\n","\n","  def __getitem__(self , index):\n","    text = self.X[index]\n","    inputs = self.tokenizer(text)\n","\n","    return {'inputs': torch.tensor(inputs , dtype=torch.int64) , 'labels': torch.tensor(self.y[index] , dtype=torch.int64)}"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1648147600848,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"},"user_tz":-540},"id":"EaTS841ruWCD","outputId":"50d1525c-33e9-4bb3-c98b-8f78bf0f0219"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.1730, 0.4242, 0.1579, 0.2450]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.1941, 0.5203, 0.0718, 0.2138]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.2368, 0.2368, 0.3586, 0.1677]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.0919, 0.3075, 0.2937, 0.3069]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.3009, 0.1867, 0.1556, 0.3569]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.2249, 0.1537, 0.4146, 0.2068]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.3367, 0.4244, 0.0543, 0.1846]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.0801, 0.1817, 0.4518, 0.2863]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.1038, 0.3213, 0.1686, 0.4063]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.3946, 0.1217, 0.1182, 0.3655]], grad_fn=<SoftmaxBackward0>)\n"]}],"source":["# ラベルベクトル\n","category_dict = {'b': 0 , 't': 1 , 'e':2 , 'm':3}\n","y_train = train['CATEGORY'].map(lambda x: category_dict[x]).values\n","y_valid = valid['CATEGORY'].map(lambda x: category_dict[x]).values\n","y_test = test['CATEGORY'].map(lambda x: category_dict[x]).values\n","\n","ds_train = CreateDataset(train['TITLE'] , y_train , tokenizer)\n","ds_valid = CreateDataset(valid['TITLE'] , y_valid , tokenizer)\n","ds_test = CreateDataset(test['TITLE'] , y_test , tokenizer)\n","\n","vocab_size = len(set(word_id.values())) + 1\n","emb_size = 300\n","padding_idx = len(set(word_id.values()))\n","output_size = 4\n","hidden_size = 50\n","\n","model = RNN(vocab_size , emb_size , padding_idx , output_size , hidden_size)\n","\n","# 先頭10件の予測値取得\n","for num in range(10):\n","  X = ds_train[num]['inputs']\n","  print(torch.softmax(model(X.unsqueeze(0)) , dim=-1))"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"9xFNbtAhKyyt","executionInfo":{"status":"ok","timestamp":1648147600848,"user_tz":-540,"elapsed":13,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"}}},"outputs":[],"source":["# 参考https://exture-ri.com/2021/01/12/pytorch-rnn/\n","# https://gotutiyan.hatenablog.com/entry/2020/09/02/200144"]},{"cell_type":"markdown","metadata":{"id":"Ybr_R3_0Jckm"},"source":["# 確率的勾配降下法による学習\n","## 確率的勾配降下法（SGD: Stochastic Gradient Descent）を用いて，問題81で構築したモデルを学習せよ．訓練データ上の損失と正解率，評価データ上の損失と正解率を表示しながらモデルを学習し，適当な基準（例えば10エポックなど）で終了させよ．"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"7Plx2-1lKyPm","executionInfo":{"status":"ok","timestamp":1648147601076,"user_tz":-540,"elapsed":2,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"}}},"outputs":[],"source":["from torch.utils.data import DataLoader\n","from torch import optim\n","\n","def acc(model , dataset , device =None , criterion = None):\n","  dataloader = DataLoader(dataset , batch_size = 1 , shuffle=False)\n","  loss = 0.0\n","  total = 0\n","  correct = 0\n","  with torch.no_grad():\n","    for data in dataloader:\n","      \n","      inputs = data['inputs'].to(device)#gpu\n","      labels = data['labels'].to(device)#gpu\n","      outputs = model(inputs)#計算\n","      if criterion != None:\n","        loss += criterion(outputs, labels).item()#loss\n","        #正解率\n","      pred = torch.argmax(outputs , dim=-1)\n","      total += len(inputs)\n","      correct += (pred == labels).sum().item()\n","      \n","  return loss / len(dataset) , correct / total\n","  \n","\n","def train_model(dataset_train , dataset_valid , batch_size , model , criterion , op , num_epochs , collate_fn = None , device = None):\n","  model.to(device)\n","  dataloader_train = DataLoader(dataset_train , batch_size = batch_size , shuffle=True , collate_fn = collate_fn)\n","  dataloader_valid = DataLoader(dataset_valid , batch_size = 1, shuffle = False)\n","  scheduler = optim.lr_scheduler.CosineAnnealingLR(op , num_epochs , eta_min=1e-3, last_epoch = -1)\n","  loss_train_list = []\n","  loss_valid_list = []\n","\n","  for epoch in range(num_epochs):\n","    model.train()\n","    for data in dataloader_train:\n","      op.zero_grad()#初期化\n","      inputs = data['inputs'].to(device)#gpu\n","      labels = data['labels'].to(device)#gpu\n","      #計算\n","      outputs = model.forward(inputs)\n","      loss = criterion(outputs, labels)\n","      loss.backward()#調節\n","      op.step()#更新\n","    \n","    model.eval()\n","\n","    # 損失と正解率の算出\n","    loss_train , acc_train = acc(model , dataset_train , device , criterion = criterion)\n","    loss_valid , acc_valid = acc(model , dataset_valid , device , criterion = criterion)\n","    loss_train_list.append([loss_train , acc_train])\n","    loss_valid_list.append([loss_valid , acc_valid])\n","\n","    #パラメータ保存\n","    torch.save({'epoch': epoch , 'model_state_dict': model.state_dict() , 'optimizer_state_dict': op.state_dict()} , f'checkpoint{epoch + 1}.pt')\n","\n","    #正答率誤算などの算出\n","    print(f'epoch: {epoch + 1}, loss_train: {loss_train:.4f}, acc_train: {acc_train:.4f}, loss_valid: {loss_valid:.4f}, acc_valid: {acc_valid:.4f}') \n","      \n","    scheduler.step()\n","\n","  return {'train': loss_train, 'valid': loss_valid}"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":209874,"status":"ok","timestamp":1648147810949,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"},"user_tz":-540},"id":"f5vSVETA2pL-","outputId":"84df9538-c702-4ddd-f9a9-750af7ee344a"},"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 1, loss_train: 1.0963, acc_train: 0.5208, loss_valid: 1.1103, acc_valid: 0.5217\n","epoch: 2, loss_train: 0.9395, acc_train: 0.6363, loss_valid: 0.9795, acc_valid: 0.6079\n","epoch: 3, loss_train: 0.7186, acc_train: 0.7396, loss_valid: 0.7964, acc_valid: 0.7189\n"]}],"source":["vocab_size = len(set(word_id.values())) + 1\n","emb_size = 300\n","padding_idx = len(set(word_id.values()))\n","output_size = 4\n","hidden_size = 50\n","learning_rate = 1e-3\n","batch_size = 1\n","num_epochs = 3#testのため回数少なめ\n","\n","model = RNN(vocab_size , emb_size , padding_idx , output_size , hidden_size)\n","CE = nn.CrossEntropyLoss()\n","op = torch.optim.SGD(model.parameters() , lr = learning_rate)\n","\n","log = train_model(ds_train , ds_valid , batch_size , model , CE , op , num_epochs)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"HHAgvIA7VEPs","executionInfo":{"status":"ok","timestamp":1648147810950,"user_tz":-540,"elapsed":13,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"}}},"outputs":[],"source":["# https://note.nkmk.me/python-pytorch-device-to-cuda-cpu/\n","# https://runebook.dev/ja/docs/pytorch/generated/torch.nn.bcewithlogitsloss\n","# https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html\n","# https://tips-memo.com/python-diff-bce"]},{"cell_type":"markdown","metadata":{"id":"v2PtIrKWJcmi"},"source":["# ミニバッチ化・GPU上での学習\n","## 問題82のコードを改変し，B事例ごとに損失・勾配を計算して学習を行えるようにせよ（Bの値は適当に選べ）．また，GPU上で学習を実行せよ．"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"XJZk_XGx7m87","executionInfo":{"status":"ok","timestamp":1648147810951,"user_tz":-540,"elapsed":13,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"}}},"outputs":[],"source":["class Padsequence():\n","  def __init__(self, padding_idx):\n","    self.padding_idx = padding_idx\n","\n","  def __call__(self, batch):\n","    sorted_batch = sorted(batch, key=lambda x: x['inputs'].shape[0], reverse=True)\n","    sequences = [x['inputs'] for x in sorted_batch]\n","    sequences_padded = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True, padding_value=self.padding_idx)\n","    labels = torch.LongTensor([x['labels'] for x in sorted_batch])\n","\n","    return {'inputs': sequences_padded, 'labels': labels}"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22256,"status":"ok","timestamp":1648147833194,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"},"user_tz":-540},"id":"1YYLgaRh8WpJ","outputId":"fe5ae8e0-19be-41dc-b3e4-64b7a8f9f229"},"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 1, loss_train: 1.4867, acc_train: 0.2546, loss_valid: 1.4858, acc_valid: 0.2579\n","epoch: 2, loss_train: 1.3978, acc_train: 0.3071, loss_valid: 1.3949, acc_valid: 0.3073\n","epoch: 3, loss_train: 1.3337, acc_train: 0.3513, loss_valid: 1.3303, acc_valid: 0.3501\n"]}],"source":["vocab_size = len(set(word_id.values())) + 1\n","emb_size = 300\n","padding_idx = len(set(word_id.values()))\n","output_size = 4\n","hidden_size = 50\n","learning_rate = 1e-3\n","batch_size = 50\n","num_epochs = 3#testのため回数少なめ\n","\n","model = RNN(vocab_size , emb_size , padding_idx , output_size , hidden_size)\n","CE = nn.CrossEntropyLoss()\n","op = torch.optim.SGD(model.parameters() , lr = learning_rate)\n","# device = torch.device('cuda')#gpu\n","device = torch.device('cpu')#gpuに制限がかかったのでcpu\n","\n","log = train_model(ds_train , ds_valid , batch_size , model , CE , op , num_epochs , collate_fn = Padsequence(padding_idx) , device = device)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"j8myAgh79Bn9","executionInfo":{"status":"ok","timestamp":1648147833195,"user_tz":-540,"elapsed":14,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"}}},"outputs":[],"source":["# 参考https://atmarkit.itmedia.co.jp/ait/articles/2008/28/news030.html"]},{"cell_type":"markdown","metadata":{"id":"-HVipbmRJcoz"},"source":["# 単語ベクトルの導入\n","## 事前学習済みの単語ベクトル（例えば，Google Newsデータセット（約1,000億単語）での学習済み単語ベクトル）で単語埋め込みemb(x)を初期化し，学習せよ．"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"t9DUNeZMKxHc","executionInfo":{"status":"ok","timestamp":1648147833195,"user_tz":-540,"elapsed":13,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"}}},"outputs":[],"source":["# ダウンロード制限がかかっているのでprthを指定する\n","# ! pip install --upgrade gdown\n","# import gdown\n","# gdown.download('https://drive.google.com/u/0/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&export=download', './GoogleNews-vectors-negative300.bin.gz', quiet=False)\n","# #model\n","# from gensim.models import KeyedVectors\n","\n","# # 学習済みモデルのロード\n","# model = KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin.gz' , binary=True)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"YDSGA8QAVQt9","executionInfo":{"status":"ok","timestamp":1648147980682,"user_tz":-540,"elapsed":147499,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"}}},"outputs":[],"source":["# 直接pathを指定する場合\n","from gensim.models import KeyedVectors\n","model_kv = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/Tutorial/NLP_100/GoogleNews-vectors-negative300.bin.gz' , binary=True)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"DMMLdQGXtADB","executionInfo":{"status":"ok","timestamp":1648147980683,"user_tz":-540,"elapsed":12,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"}}},"outputs":[],"source":["import numpy as np\n","\n","vocab_size = len(set(word_id.values())) + 1\n","emb_size = 300\n","weights = np.zeros((vocab_size , emb_size))\n","words_in_pretrained = 0\n","for idx , word in enumerate(word_id.keys()):\n","  try:\n","    weights[idx] = model_kv[word]\n","    words_in_pretrained += 1\n","  except KeyError:\n","    weights[idx] = np.random.normal(    loc   = 0 , scale = 1 , size=(emb_size ,))#正規化\n","weights = torch.from_numpy(weights.astype((np.float32)))#torch"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"Zm1HSzW6v_QK","executionInfo":{"status":"ok","timestamp":1648147980683,"user_tz":-540,"elapsed":11,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"}}},"outputs":[],"source":["class RNN(nn.Module):\n","  def __init__(self , vocab_size , emb_size , padding_idx , output_size , hidden_size , num_layers , emb_weights = None , bidirectional = False):\n","    super().__init__()\n","    self.hidden_size = hidden_size\n","    self.num_layers = num_layers\n","    self.num_directions = bidirectional + 1\n","\n","    if emb_weights != None:\n","      self.emb = nn.Embedding.from_pretrained(emb_weights, padding_idx=padding_idx)\n","    else:\n","      self.emb = nn.Embedding(vocab_size, emb_size, padding_idx=padding_idx)\n","\n","    self.rnn = nn.RNN(emb_size , hidden_size , num_layers , nonlinearity='relu' , bidirectional = bidirectional , batch_first = True)\n","    self.fc = nn.Linear(hidden_size * self.num_directions , output_size)\n","    \n","  def forward(self, x):\n","    self.batch_size = x.size()[0]\n","    hidden = self.init_hidden()\n","    emb = self.emb(x)\n","    out, hidden = self.rnn(emb, hidden)\n","    out = self.fc(out[: , -1 , :])\n","    return out\n","    \n","  def init_hidden(self):\n","    hidden = torch.zeros(self.num_layers * self.num_directions , self.batch_size , self.hidden_size)\n","    return hidden"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19050,"status":"ok","timestamp":1648147999722,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"},"user_tz":-540},"id":"YhaFJc6NwB7h","outputId":"2aff28d9-7d6e-434b-905d-abea57bb593d"},"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 1, loss_train: 1.3848, acc_train: 0.2868, loss_valid: 1.3950, acc_valid: 0.2609\n","epoch: 2, loss_train: 1.3442, acc_train: 0.3618, loss_valid: 1.3514, acc_valid: 0.3358\n","epoch: 3, loss_train: 1.3117, acc_train: 0.3794, loss_valid: 1.3168, acc_valid: 0.3681\n"]}],"source":["vocab_size = len(set(word_id.values())) + 1\n","emb_size = 300\n","padding_idx = len(set(word_id.values()))\n","output_size = 4\n","hidden_size = 50\n","num_layers = 1\n","learning_rate = 1e-3\n","batch_size = 50\n","num_epochs = 3#testのため回数少なめ\n","\n","model = RNN(vocab_size , emb_size , padding_idx , output_size , hidden_size , num_layers , emb_weights = weights)\n","CE = nn.CrossEntropyLoss()\n","op = torch.optim.SGD(model.parameters() , lr = learning_rate)\n","# device = torch.device('cuda')#gpu\n","device = torch.device('cpu')#gpuに制限がかかったのでcpu\n","\n","log = train_model(ds_train , ds_valid , batch_size , model , CE , op , num_epochs , collate_fn = Padsequence(padding_idx) , device = device)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"S7F_W9ROw4kM","executionInfo":{"status":"ok","timestamp":1648147999723,"user_tz":-540,"elapsed":11,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"}}},"outputs":[],"source":["# 参考https://www.sejuku.net/blog/73026\n","# https://note.nkmk.me/python-numpy-dtype-astype/"]},{"cell_type":"markdown","metadata":{"id":"iVxcSaQHJcq3"},"source":["# 双方向RNN・多層化\n","## \n","順方向と逆方向のRNNの両方を用いて入力テキストをエンコードし，モデルを学習せよ．\n","\n","h⃖ T+1=0,h⃖ t=RNN←−−−(emb(xt),h⃖ t+1),y=softmax(W(yh)[h→T;h⃖ 1]+b(y))\n","ただし，h→t∈ℝdh,h⃖ t∈ℝdhはそれぞれ，順方向および逆方向のRNNで求めた時刻tの隠れ状態ベクトル，RNN←−−−(x,h)は入力xと次時刻の隠れ状態hから前状態を計算するRNNユニット，W(yh)∈ℝL×2dhは隠れ状態ベクトルからカテゴリを予測するための行列，b(y)∈ℝLはバイアス項である．また，[a;b]はベクトルaとbの連結を表す。\n","\n","さらに，双方向RNNを多層化して実験せよ．"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":76388,"status":"ok","timestamp":1648148076100,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"},"user_tz":-540},"id":"z5P4B_uEKwSJ","outputId":"f6de263e-5b8a-4800-c833-75898600cfab"},"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 1, loss_train: 1.3380, acc_train: 0.3966, loss_valid: 1.3386, acc_valid: 0.3951\n","epoch: 2, loss_train: 1.2850, acc_train: 0.3982, loss_valid: 1.2854, acc_valid: 0.3996\n","epoch: 3, loss_train: 1.2421, acc_train: 0.3978, loss_valid: 1.2424, acc_valid: 0.3988\n"]}],"source":["vocab_size = len(set(word_id.values())) + 1\n","emb_size = 300\n","padding_idx = len(set(word_id.values()))\n","output_size = 4\n","hidden_size = 50\n","num_layers = 5#ここで多層化\n","learning_rate = 1e-3\n","batch_size = 50\n","num_epochs = 3#testのため回数少なめ\n","\n","model = RNN(vocab_size , emb_size , padding_idx , output_size , hidden_size , num_layers , emb_weights = weights , bidirectional = True)#bidirectional = Trueで双方向\n","CE = nn.CrossEntropyLoss()\n","op = optim.SGD(model.parameters() , lr = learning_rate)\n","# device = torch.device('cuda')#gpu\n","device = torch.device('cpu')#gpuに制限がかかったのでcpu\n","\n","log = train_model(ds_train , ds_valid , batch_size , model , CE , op , num_epochs , collate_fn = Padsequence(padding_idx) , device = device)"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"4orHQA2b2hR9","executionInfo":{"status":"ok","timestamp":1648148076101,"user_tz":-540,"elapsed":19,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"}}},"outputs":[],"source":["# 参考https://qiita.com/m__k/items/78a5125d719951ca98d3\n","# https://axa.biopapyrus.jp/deep-learning/rnn/brnn.html\n","# https://deepage.net/deep_learning/2017/05/23/recurrent-neural-networks.html\n","# https://teratail.com/questions/185713\n","# https://qiita.com/tetsuro_skiing/items/87c0c37cefd7b601f974"]},{"cell_type":"markdown","metadata":{"id":"wMhQ_gsMJctM"},"source":["#  畳み込みニューラルネットワーク (CNN)\n","## ID番号で表現された単語列x=(x1,x2,…,xT)がある．ただし，Tは単語列の長さ，xt∈ℝVは単語のID番号のone-hot表記である（Vは単語の総数である）．畳み込みニューラルネットワーク（CNN: Convolutional Neural Network）を用い，単語列xからカテゴリyを予測するモデルを実装せよ．\n","\n","ただし，畳み込みニューラルネットワークの構成は以下の通りとする．\n","\n","単語埋め込みの次元数: dw\n","畳み込みのフィルターのサイズ: 3 トークン\n","畳み込みのストライド: 1 トークン\n","畳み込みのパディング: あり\n","畳み込み演算後の各時刻のベクトルの次元数: dh\n","畳み込み演算後に最大値プーリング（max pooling）を適用し，入力文をdh次元の隠れベクトルで表現\n","すなわち，時刻tの特徴ベクトルpt∈ℝdhは次式で表される．\n","\n","pt=g(W(px)[emb(xt−1);emb(xt);emb(xt+1)]+b(p))\n","ただし，W(px)∈ℝdh×3dw,b(p)∈ℝdhはCNNのパラメータ，gは活性化関数（例えばtanhやReLUなど），[a;b;c]はベクトルa,b,cの連結である．なお，行列W(px)の列数が3dwになるのは，3個のトークンの単語埋め込みを連結したものに対して，線形変換を行うためである．\n","\n","最大値プーリングでは，特徴ベクトルの次元毎に全時刻における最大値を取り，入力文書の特徴ベクトルc∈ℝdhを求める．c[i]でベクトルcのi番目の次元の値を表すことにすると，最大値プーリングは次式で表される．\n","\n","c[i]=max1≤t≤Tpt[i]\n","最後に，入力文書の特徴ベクトルcに行列W(yc)∈ℝL×dhとバイアス項b(y)∈ℝLによる線形変換とソフトマックス関数を適用し，カテゴリyを予測する．\n","\n","y=softmax(W(yc)c+b(y))\n","なお，この問題ではモデルの学習を行わず，ランダムに初期化された重み行列でyを計算するだけでよい．\n","\n"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"1SC8JKlo9xXa","executionInfo":{"status":"ok","timestamp":1648148076101,"user_tz":-540,"elapsed":18,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"}}},"outputs":[],"source":["# 単語埋め込みの次元数: dw\n","# 畳み込みのフィルターのサイズ: 3 トークン\n","# 畳み込みのストライド: 1 トークン\n","# 畳み込みのパディング: あり\n","# 畳み込み演算後の各時刻のベクトルの次元数: dh"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"lZ_UFaz-Kvo-","executionInfo":{"status":"ok","timestamp":1648148076102,"user_tz":-540,"elapsed":19,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"}}},"outputs":[],"source":["from torch.nn import functional as F\n","\n","class CNN(nn.Module):\n","  def __init__(self , vocab_size , emb_size , padding_idx , output_size , out_channels , kernel_heights , stride , padding , emb_weights = None):\n","    super().__init__()\n","    if emb_weights != None:\n","      self.emb = nn.Embedding.from_pretrained(emb_weights , padding_idx = padding_idx)\n","    else:\n","      self.emb = nn.Embedding(vocab_size , emb_size , padding_idx = padding_idx)\n","    self.conv = nn.Conv2d(1 , out_channels , (kernel_heights , emb_size) , stride , (padding , 0))\n","    self.drop = nn.Dropout(0.3)\n","    self.fc = nn.Linear(out_channels, output_size)\n","    \n","  def forward(self, x):\n","    emb = self.emb(x).unsqueeze(1)\n","    conv = self.conv(emb)\n","    act = F.relu(conv.squeeze(3))\n","    max_pool = F.max_pool1d(act, act.size()[2])\n","    out = self.fc(self.drop(max_pool.squeeze(2)))\n","    return out"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"slTiYPPo--EV","executionInfo":{"status":"ok","timestamp":1648148076102,"user_tz":-540,"elapsed":19,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"}}},"outputs":[],"source":["vocab_size = len(set(word_id.values())) + 1\n","emb_size = 300\n","padding_idx = len(set(word_id.values()))\n","output_size = 4\n","#CNNのパラメータ\n","out_channels =100\n","kernel_heights = 3\n","stride = 1\n","padding = 1\n","\n","model = CNN(vocab_size , emb_size , padding_idx , output_size , out_channels , kernel_heights , stride , padding , emb_weights = weights)"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1648148076102,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"},"user_tz":-540},"id":"0mwy7kvC_vId","outputId":"a3076d63-d2fd-4038-82ad-3b71d777d8c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.2496, 0.2184, 0.2293, 0.3027]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.3292, 0.2204, 0.1507, 0.2997]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.2730, 0.2025, 0.2404, 0.2841]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.3409, 0.1346, 0.1916, 0.3329]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.2808, 0.2080, 0.2482, 0.2629]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.2545, 0.2165, 0.2067, 0.3224]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.3830, 0.1757, 0.1111, 0.3301]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.2838, 0.2415, 0.1816, 0.2930]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.3962, 0.2543, 0.1292, 0.2202]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.2869, 0.2070, 0.2128, 0.2933]], grad_fn=<SoftmaxBackward0>)\n"]}],"source":["for num in range(10):\n","  X = ds_train[num]['inputs']\n","  print(torch.softmax(model(X.unsqueeze(0)) , dim=-1))"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"jhOnOGt06Ery","executionInfo":{"status":"ok","timestamp":1648148076104,"user_tz":-540,"elapsed":16,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"}}},"outputs":[],"source":["# 参考https://qiita.com/shu_marubo/items/70b20c3a6c172aaeb8de\n","# https://qiita.com/mathlive/items/8e1f9a8467fff8dfd03c\n","# https://exture-ri.com/2021/01/11/pytorch-cnn/\n","# https://qiita.com/m__k/items/6c39cfe7dfa99102fa8e\n","# https://kento1109.hatenablog.com/entry/2019/09/30/115139"]},{"cell_type":"markdown","metadata":{"id":"Ac0_YmHBJcvP"},"source":["# 確率的勾配降下法によるCNNの学習\n","## 確率的勾配降下法（SGD: Stochastic Gradient Descent）を用いて，問題86で構築したモデルを学習せよ．訓練データ上の損失と正解率，評価データ上の損失と正解率を表示しながらモデルを学習し，適当な基準（例えば10エポックなど）で終了させよ．"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29720,"status":"ok","timestamp":1648148105808,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"},"user_tz":-540},"id":"7BoDooPEKvN1","outputId":"30e1d6be-c1d9-44c6-98c3-3b1adabbb056"},"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 1, loss_train: 1.2421, acc_train: 0.4727, loss_valid: 1.2253, acc_valid: 0.4663\n","epoch: 2, loss_train: 1.2081, acc_train: 0.5047, loss_valid: 1.1996, acc_valid: 0.4805\n","epoch: 3, loss_train: 1.1859, acc_train: 0.5233, loss_valid: 1.1816, acc_valid: 0.5082\n"]}],"source":["vocab_size = len(set(word_id.values())) + 1\n","emb_size = 300\n","padding_idx = len(set(word_id.values()))\n","output_size = 4\n","#CNNのパラメータ\n","out_channels =100\n","kernel_heights = 3\n","stride = 1\n","padding = 1\n","learning_rate = 1e-3\n","batch_size = 50\n","num_epochs = 3#testのため回数少なめ\n","\n","model = CNN(vocab_size , emb_size , padding_idx , output_size , out_channels , kernel_heights , stride , padding , emb_weights = weights)\n","CE = nn.CrossEntropyLoss()\n","op = optim.SGD(model.parameters() , lr = learning_rate)\n","# device = torch.device('cuda')#gpu\n","device = torch.device('cpu')#gpuに制限がかかったのでcpu\n","\n","# モデルの学習\n","log = train_model(ds_train , ds_valid , batch_size , model , CE , op , num_epochs , collate_fn = Padsequence(padding_idx) , device = device)"]},{"cell_type":"markdown","metadata":{"id":"d_QtLlgYJcxQ"},"source":["# パラメータチューニング\n","## 問題85や問題87のコードを改変し，ニューラルネットワークの形状やハイパーパラメータを調整しながら，高性能なカテゴリ分類器を構築せよ．"]},{"cell_type":"code","source":["class RNN(nn.Module):\n","  def __init__(self , vocab_size , emb_size , padding_idx , output_size , hidden_size , num_layers , emb_weights = None , bidirectional = False):\n","    super().__init__()\n","    self.hidden_size = hidden_size\n","    self.num_layers = num_layers\n","    self.num_directions = bidirectional + 1\n","\n","    if emb_weights != None:\n","      self.emb = nn.Embedding.from_pretrained(emb_weights, padding_idx=padding_idx)\n","    else:\n","      self.emb = nn.Embedding(vocab_size, emb_size, padding_idx=padding_idx)\n","\n","    self.rnn = nn.RNN(emb_size , hidden_size , num_layers , nonlinearity='relu' , bidirectional = bidirectional , batch_first = True)\n","    self.fc = nn.Linear(hidden_size * self.num_directions , output_size)\n","    \n","  def forward(self, x):\n","    self.batch_size = x.size()[0]\n","    hidden = self.init_hidden()\n","    emb = self.emb(x)\n","    out, hidden = self.rnn(emb, hidden)\n","    out = self.fc(out[: , -1 , :])\n","    return out\n","    \n","  def init_hidden(self):\n","    hidden = torch.zeros(self.num_layers * self.num_directions , self.batch_size , self.hidden_size)\n","    return hidden"],"metadata":{"id":"PBgntiKP6C8C","executionInfo":{"status":"ok","timestamp":1648148105808,"user_tz":-540,"elapsed":12,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["vocab_size = len(set(word_id.values())) + 1\n","emb_size = 300\n","padding_idx = len(set(word_id.values()))\n","output_size = 4\n","hidden_size = 50\n","num_layers = 10#多い法が良い？\n","learning_rate = 1e-3#小さい方がいい？\n","batch_size = 128#適度に増やす\n","num_epochs = 50#多めに\n","\n","model = RNN(vocab_size , emb_size , padding_idx , output_size , hidden_size , num_layers , emb_weights = weights , bidirectional = True)\n","CE = nn.CrossEntropyLoss()\n","op = optim.SGD(model.parameters() , lr = learning_rate)\n","# device = torch.device('cuda')#gpu\n","device = torch.device('cpu')#gpuに制限がかかったのでcpu\n","\n","log = train_model(ds_train , ds_valid , batch_size , model , CE , op , num_epochs , collate_fn = Padsequence(padding_idx) , device = device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QudC7shH6L4r","executionInfo":{"status":"ok","timestamp":1648150452519,"user_tz":-540,"elapsed":2346722,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"}},"outputId":"caa881cb-86b7-483b-de99-07e22b2746a4"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 1, loss_train: 1.3852, acc_train: 0.3953, loss_valid: 1.3851, acc_valid: 0.3951\n","epoch: 2, loss_train: 1.3603, acc_train: 0.3957, loss_valid: 1.3603, acc_valid: 0.3958\n","epoch: 3, loss_train: 1.3375, acc_train: 0.3957, loss_valid: 1.3375, acc_valid: 0.3958\n","epoch: 4, loss_train: 1.3160, acc_train: 0.3957, loss_valid: 1.3160, acc_valid: 0.3958\n","epoch: 5, loss_train: 1.2956, acc_train: 0.3957, loss_valid: 1.2956, acc_valid: 0.3958\n","epoch: 6, loss_train: 1.2769, acc_train: 0.3957, loss_valid: 1.2770, acc_valid: 0.3958\n","epoch: 7, loss_train: 1.2598, acc_train: 0.3957, loss_valid: 1.2599, acc_valid: 0.3958\n","epoch: 8, loss_train: 1.2441, acc_train: 0.3957, loss_valid: 1.2442, acc_valid: 0.3958\n","epoch: 9, loss_train: 1.2298, acc_train: 0.3994, loss_valid: 1.2299, acc_valid: 0.4063\n","epoch: 10, loss_train: 1.2169, acc_train: 0.4224, loss_valid: 1.2171, acc_valid: 0.4220\n","epoch: 11, loss_train: 1.2058, acc_train: 0.4223, loss_valid: 1.2060, acc_valid: 0.4220\n","epoch: 12, loss_train: 1.1964, acc_train: 0.4219, loss_valid: 1.1966, acc_valid: 0.4213\n","epoch: 13, loss_train: 1.1885, acc_train: 0.4219, loss_valid: 1.1888, acc_valid: 0.4213\n","epoch: 14, loss_train: 1.1822, acc_train: 0.4219, loss_valid: 1.1825, acc_valid: 0.4213\n","epoch: 15, loss_train: 1.1773, acc_train: 0.4219, loss_valid: 1.1776, acc_valid: 0.4213\n","epoch: 16, loss_train: 1.1733, acc_train: 0.4219, loss_valid: 1.1738, acc_valid: 0.4213\n","epoch: 17, loss_train: 1.1703, acc_train: 0.4219, loss_valid: 1.1708, acc_valid: 0.4213\n","epoch: 18, loss_train: 1.1681, acc_train: 0.4219, loss_valid: 1.1686, acc_valid: 0.4213\n","epoch: 19, loss_train: 1.1665, acc_train: 0.4219, loss_valid: 1.1670, acc_valid: 0.4213\n","epoch: 20, loss_train: 1.1653, acc_train: 0.4219, loss_valid: 1.1658, acc_valid: 0.4213\n","epoch: 21, loss_train: 1.1645, acc_train: 0.4219, loss_valid: 1.1650, acc_valid: 0.4213\n","epoch: 22, loss_train: 1.1638, acc_train: 0.4219, loss_valid: 1.1644, acc_valid: 0.4213\n","epoch: 23, loss_train: 1.1634, acc_train: 0.4219, loss_valid: 1.1639, acc_valid: 0.4213\n","epoch: 24, loss_train: 1.1631, acc_train: 0.4219, loss_valid: 1.1636, acc_valid: 0.4213\n","epoch: 25, loss_train: 1.1629, acc_train: 0.4219, loss_valid: 1.1634, acc_valid: 0.4213\n","epoch: 26, loss_train: 1.1627, acc_train: 0.4219, loss_valid: 1.1632, acc_valid: 0.4213\n","epoch: 27, loss_train: 1.1626, acc_train: 0.4219, loss_valid: 1.1631, acc_valid: 0.4213\n","epoch: 28, loss_train: 1.1625, acc_train: 0.4219, loss_valid: 1.1630, acc_valid: 0.4213\n","epoch: 29, loss_train: 1.1624, acc_train: 0.4219, loss_valid: 1.1629, acc_valid: 0.4213\n","epoch: 30, loss_train: 1.1623, acc_train: 0.4219, loss_valid: 1.1629, acc_valid: 0.4213\n","epoch: 31, loss_train: 1.1623, acc_train: 0.4219, loss_valid: 1.1628, acc_valid: 0.4213\n","epoch: 32, loss_train: 1.1622, acc_train: 0.4219, loss_valid: 1.1628, acc_valid: 0.4213\n","epoch: 33, loss_train: 1.1622, acc_train: 0.4219, loss_valid: 1.1627, acc_valid: 0.4213\n","epoch: 34, loss_train: 1.1621, acc_train: 0.4219, loss_valid: 1.1627, acc_valid: 0.4213\n","epoch: 35, loss_train: 1.1621, acc_train: 0.4219, loss_valid: 1.1627, acc_valid: 0.4213\n","epoch: 36, loss_train: 1.1621, acc_train: 0.4219, loss_valid: 1.1626, acc_valid: 0.4213\n","epoch: 37, loss_train: 1.1621, acc_train: 0.4219, loss_valid: 1.1626, acc_valid: 0.4213\n","epoch: 38, loss_train: 1.1620, acc_train: 0.4219, loss_valid: 1.1626, acc_valid: 0.4213\n","epoch: 39, loss_train: 1.1620, acc_train: 0.4219, loss_valid: 1.1626, acc_valid: 0.4213\n","epoch: 40, loss_train: 1.1620, acc_train: 0.4219, loss_valid: 1.1626, acc_valid: 0.4213\n","epoch: 41, loss_train: 1.1620, acc_train: 0.4219, loss_valid: 1.1625, acc_valid: 0.4213\n","epoch: 42, loss_train: 1.1620, acc_train: 0.4219, loss_valid: 1.1625, acc_valid: 0.4213\n","epoch: 43, loss_train: 1.1620, acc_train: 0.4219, loss_valid: 1.1625, acc_valid: 0.4213\n","epoch: 44, loss_train: 1.1620, acc_train: 0.4219, loss_valid: 1.1625, acc_valid: 0.4213\n","epoch: 45, loss_train: 1.1620, acc_train: 0.4219, loss_valid: 1.1625, acc_valid: 0.4213\n","epoch: 46, loss_train: 1.1620, acc_train: 0.4219, loss_valid: 1.1625, acc_valid: 0.4213\n","epoch: 47, loss_train: 1.1620, acc_train: 0.4219, loss_valid: 1.1625, acc_valid: 0.4213\n","epoch: 48, loss_train: 1.1620, acc_train: 0.4219, loss_valid: 1.1625, acc_valid: 0.4213\n","epoch: 49, loss_train: 1.1620, acc_train: 0.4219, loss_valid: 1.1625, acc_valid: 0.4213\n","epoch: 50, loss_train: 1.1619, acc_train: 0.4219, loss_valid: 1.1625, acc_valid: 0.4213\n"]}]},{"cell_type":"code","execution_count":31,"metadata":{"id":"pNYDnFE_EfYg","executionInfo":{"status":"ok","timestamp":1648150452520,"user_tz":-540,"elapsed":18,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"}}},"outputs":[],"source":["# 参考https://qiita.com/nyanko-box/items/a6f50e28383a5bd0a432\n","# https://cpp-learning.com/optuna-pytorch/\n","# https://qiita.com/Yushi1958/items/cd22ade638f7e292e520\n","# https://dreamer-uma.com/pytorch-optuna-hyperparameter-tuning/\n","# http://maruo51.com/2020/08/07/optuna_pytorch/\n","# https://ichi.pro/optuna-o-shiyoshita-pytorch-haipa-parame-ta-no-chosei-4883072668892"]},{"cell_type":"markdown","metadata":{"id":"es6FbyNdJczi"},"source":["# 事前学習済み言語モデルからの転移学習\n","## 事前学習済み言語モデル（例えばBERTなど）を出発点として，ニュース記事見出しをカテゴリに分類するモデルを構築せよ．"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"VlgIx1syKuK-","executionInfo":{"status":"ok","timestamp":1648150452520,"user_tz":-540,"elapsed":8,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"}}},"outputs":[],"source":["# !pip install -q transformers\n","# from transformers import BertTokenizer, BertModel\n","# from torch import cuda"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"rfL9OG1rEehF","executionInfo":{"status":"ok","timestamp":1648150452521,"user_tz":-540,"elapsed":8,"user":{"displayName":"Tatsuki Okada","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310138447043973112"}}},"outputs":[],"source":["# https://note.nkmk.me/python-pytorch-device-to-cuda-cpu/\n","# https://qiita.com/yamaru/items/63a342c844cff056a549\n","# https://qiita.com/m__k/items/e312ddcf9a3d0ea64d72\n","# https://scrapbox.io/miyamonz/pytorch,_transformers%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9FBERT%E3%81%AEfine-tuning%E3%81%AE%E6%96%B9%E6%B3%95"]}],"metadata":{"colab":{"name":"NLP_100_9.ipynb","provenance":[],"authorship_tag":"ABX9TyMxoWzvhe8xUqAxdieOXwBe"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":0}